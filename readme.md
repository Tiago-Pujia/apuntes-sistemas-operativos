# üìò Introducci√≥n

> Material de cursada de la materia **Sistemas Operativos**  
> üìÖ Inicio: 09/04/2025  
> üéì Alumno: Tiago Pujia | üë®‚Äçüè´ Prof: Alexis Villamayor  
> üïî Comisi√≥n 3900 [3 = Miercoles, 9 = Turno noche]
> ‚ñ∂Ô∏è [Clases Grabadas](https://www.youtube.com/)

## Indice

- [üìò Introducci√≥n](#-introducci√≥n)
  - [Indice](#indice)
- [Modulo 1: Introducci√≥n a los Sistemas Operativos](#modulo-1-introducci√≥n-a-los-sistemas-operativos)
  - [¬øQue es un sistema operativo?](#que-es-un-sistema-operativo)
    - [¬øPor qu√© estudiar los sistemas operatiovs?](#por-qu√©-estudiar-los-sistemas-operatiovs)
  - [Funciones y Objetivos](#funciones-y-objetivos)
    - [Inicializaci√≥n (proceso de arranque)](#inicializaci√≥n-proceso-de-arranque)
    - [Maquina Extendida (Interfaz)](#maquina-extendida-interfaz)
    - [Administraci√≥n de recursos](#administraci√≥n-de-recursos)
    - [Aislamiento](#aislamiento)
    - [Seguridad](#seguridad)
  - [Clasificaciones de Sistemas Operativos](#clasificaciones-de-sistemas-operativos)
    - [Segun la Cantidad de Usuarios](#segun-la-cantidad-de-usuarios)
    - [Segun la Cantidad de Procesadores que Soporta](#segun-la-cantidad-de-procesadores-que-soporta)
    - [Segun la Cantidad de Tareas que Sucesivas](#segun-la-cantidad-de-tareas-que-sucesivas)
    - [Segun sus Aplicaciones (Usos)](#segun-sus-aplicaciones-usos)
    - [Segun la Organizaci√≥n de su Arquitectura](#segun-la-organizaci√≥n-de-su-arquitectura)
  - [Interrupciones](#interrupciones)
    - [Definici√≥n](#definici√≥n)
    - [Clasificaci√≥n](#clasificaci√≥n)
      - [Segun prioridad](#segun-prioridad)
      - [Segun su origen](#segun-su-origen)
    - [Diferencia Interrupci√≥n y Excepci√≥n](#diferencia-interrupci√≥n-y-excepci√≥n)
    - [Funciones y Objetivos](#funciones-y-objetivos-1)
  - [Modos de Ejecucion de los Procesos](#modos-de-ejecucion-de-los-procesos)
  - [Definiciones Computo Distribuido](#definiciones-computo-distribuido)
- [Modulo 2: De Programas a Procesos](#modulo-2-de-programas-a-procesos)
  - [Conceptos Basicos](#conceptos-basicos)
  - [Entidad Pasiva y Activa](#entidad-pasiva-y-activa)
  - [Compilaci√≥n y Carga de un Proceso](#compilaci√≥n-y-carga-de-un-proceso)
  - [Procesos y Thread](#procesos-y-thread)
  - [Administraci√≥n de Procesos](#administraci√≥n-de-procesos)
    - [Estructura Memoria CPU](#estructura-memoria-cpu)
    - [Bloque de Control (PCB)](#bloque-de-control-pcb)
    - [Cambio de Contexto y Proceso](#cambio-de-contexto-y-proceso)
    - [Objetivos del PCB](#objetivos-del-pcb)
    - [Contenido del PCB](#contenido-del-pcb)
  - [Transici√≥n de Estados de un Proceso](#transici√≥n-de-estados-de-un-proceso)
    - [Tipos de Estados](#tipos-de-estados)
    - [Diagrama de Proceso](#diagrama-de-proceso)
      - [Modelo 7 Estados](#modelo-7-estados)
      - [Modelo 5 Estados](#modelo-5-estados)
    - [Colas](#colas)
    - [Clasificaci√≥n Estados](#clasificaci√≥n-estados)
    - [Razones de un Cambio de Estado de Proceso](#razones-de-un-cambio-de-estado-de-proceso)
  - [Creaci√≥n de Procesos](#creaci√≥n-de-procesos)
    - [Razones para crear un proceso](#razones-para-crear-un-proceso)
    - [Tipos de Creacion de Procesos](#tipos-de-creacion-de-procesos)
    - [Secuencia de creaci√≥n de un proceso](#secuencia-de-creaci√≥n-de-un-proceso)
    - [Finalizar de un proceso](#finalizar-de-un-proceso)
  - [Hilos](#hilos)
    - [Definici√≥n](#definici√≥n-1)
    - [Caracteristicas](#caracteristicas)
    - [Ventajas respecto a los Procesos](#ventajas-respecto-a-los-procesos)
    - [Implementaci√≥n de Hilos](#implementaci√≥n-de-hilos)
      - [Hilos a Nivel de Usuario (ULT)](#hilos-a-nivel-de-usuario-ult)
      - [Hilos a Nivel de Kernel (KLT)](#hilos-a-nivel-de-kernel-klt)
    - [Estado de los Hilos](#estado-de-los-hilos)
    - [Patrones de Trabajo con Hilos](#patrones-de-trabajo-con-hilos)
  - [Fibra](#fibra)
    - [Definici√≥n](#definici√≥n-2)
    - [Caracteristicas](#caracteristicas-1)
    - [Ventajas](#ventajas)
- [Modulo 3: Planificaci√≥n de Procesos](#modulo-3-planificaci√≥n-de-procesos)
  - [Definici√≥n](#definici√≥n-3)
  - [Objetivos](#objetivos)
  - [Tipos de Planificaci√≥n](#tipos-de-planificaci√≥n)
  - [Relaci√≥n entre Tipos Planificadores y Estados de los Procesos](#relaci√≥n-entre-tipos-planificadores-y-estados-de-los-procesos)
  - [Tipos de procesos](#tipos-de-procesos)
  - [Mediendo las respuestas](#mediendo-las-respuestas)
    - [Unidades de Medici√≥n](#unidades-de-medici√≥n)
    - [M√©tricas Utilizadas](#m√©tricas-utilizadas)
  - [Clasificaci√≥n Algoritmos de Planificaci√≥n](#clasificaci√≥n-algoritmos-de-planificaci√≥n)
    - [Primero en Llegar, Primero Servido (FCFS) (Procesos Secuenciales)](#primero-en-llegar-primero-servido-fcfs-procesos-secuenciales)
    - [Round Robin (multiprogramaci√≥n)](#round-robin-multiprogramaci√≥n)
    - [El Proceso m√°s Corto a Continuaci√≥n (SPN, Shortest Process Next)](#el-proceso-m√°s-corto-a-continuaci√≥n-spn-shortest-process-next)
    - [El m√°s Penalizado a Continuaci√≥n (HPRN, Highest Penality Ratio Next)](#el-m√°s-penalizado-a-continuaci√≥n-hprn-highest-penality-ratio-next)
    - [Ronda Egoista (SRR)](#ronda-egoista-srr)
    - [Algoritmos con M√∫ltiples Colas de Listos](#algoritmos-con-m√∫ltiples-colas-de-listos)
    - [Retroalimentaci√≥n Multinivel (FB)](#retroalimentaci√≥n-multinivel-fb)
    - [Ronda Loteria (RR)](#ronda-loteria-rr)
    - [Algoritmos H√≠bridos](#algoritmos-h√≠bridos)
  - [Planificaci√≥n de Hilos](#planificaci√≥n-de-hilos)
  - [Planificaci√≥n Multiprocesador](#planificaci√≥n-multiprocesador)
    - [Afinidad a Procesador](#afinidad-a-procesador)
    - [Balanceo de Cargas](#balanceo-de-cargas)
- [Practica Planificaci√≥n](#practica-planificaci√≥n)
  - [Modelo de Planificaci√≥n de Procesos - Diagrama de Gantt](#modelo-de-planificaci√≥n-de-procesos---diagrama-de-gantt)
    - [Definici√≥n](#definici√≥n-4)
    - [Utilidades del diagrama:](#utilidades-del-diagrama)
    - [Modelo de transici√≥n de estados de procesos](#modelo-de-transici√≥n-de-estados-de-procesos)
    - [Construcci√≥n](#construcci√≥n)
    - [Trazas y Rafagas](#trazas-y-rafagas)
    - [Prioridades y PCP](#prioridades-y-pcp)
    - [Parametros](#parametros)
  - [Ejercicio 1](#ejercicio-1)
    - [Consigna:](#consigna)
    - [Soluci√≥n final](#soluci√≥n-final)
  - [Ejercicio 2](#ejercicio-2)
    - [Consigna](#consigna-1)
    - [Soluci√≥n Final](#soluci√≥n-final-1)
  - [Ejercicio 3](#ejercicio-3)
    - [Consigna](#consigna-2)
    - [Soluci√≥n Final](#soluci√≥n-final-2)
- [Modulo 4: Sincronizaci√≥n y Comunicaci√≥n entre procesos](#modulo-4-sincronizaci√≥n-y-comunicaci√≥n-entre-procesos)
  - [¬øPorque?](#porque)
  - [Problemas Concurrentes](#problemas-concurrentes)
  - [Concurrencia](#concurrencia)
  - [Grafos de Precedencia](#grafos-de-precedencia)
    - [Condiciones de Bernstein](#condiciones-de-bernstein)
  - [Especificaci√≥n Concurrente](#especificaci√≥n-concurrente)
    - [Instrucciones FORK y JOIN](#instrucciones-fork-y-join)
  - [Algunos Conceptos](#algunos-conceptos)
    - [Conceptos](#conceptos)
  - [Regi√≥n Critica](#regi√≥n-critica)
  - [Algoritmos para Proteger la Regi√≥n Critica](#algoritmos-para-proteger-la-regi√≥n-critica)
    - [1. Algoritmo de Sincronizaci√≥n con Espera Activa](#1-algoritmo-de-sincronizaci√≥n-con-espera-activa)
    - [2. Alternancia Estricta (Turnos)](#2-alternancia-estricta-turnos)
    - [3. Instrucciones At√≥micas de Hardware](#3-instrucciones-at√≥micas-de-hardware)
    - [4. Instrucci√≥n Intercambiar (CAS: Compare And Swap)](#4-instrucci√≥n-intercambiar-cas-compare-and-swap)
    - [5. Algoritmos Que no se Utilizan](#5-algoritmos-que-no-se-utilizan)
    - [6. Semaforos](#6-semaforos)
      - [Definici√≥n](#definici√≥n-5)
      - [Tipo](#tipo)
      - [Semaforos con/sin espera activa](#semaforos-consin-espera-activa)
  - [Comunicaci√≥n Entre Procesos (IPC)](#comunicaci√≥n-entre-procesos-ipc)
    - [Formas de Comunicaci√≥n](#formas-de-comunicaci√≥n)
    - [Tipos de Sincronizaciones Mediantes Mensajes](#tipos-de-sincronizaciones-mediantes-mensajes)
    - [Modelo Producto-Consumidor (secuencia FIFO)](#modelo-producto-consumidor-secuencia-fifo)
      - [Con sleep() \& wakeup()](#con-sleep--wakeup)
      - [Con Contadores de eventos](#con-contadores-de-eventos)
      - [Con Sem√°foros¬†](#con-sem√°foros)
  - [Bloqueos Mutuos (DeadLocks)](#bloqueos-mutuos-deadlocks)
    - [Definici√≥n](#definici√≥n-6)
    - [Grafo de Asignaci√≥n de Recursos (Resource Allocation Graph )](#grafo-de-asignaci√≥n-de-recursos-resource-allocation-graph-)
    - [Condiciones Necesarias de Coffman](#condiciones-necesarias-de-coffman)
    - [Estrategias para Tratar los Bloqueos](#estrategias-para-tratar-los-bloqueos)
      - [Ignorarlos y Pensar que nunca ocurrio](#ignorarlos-y-pensar-que-nunca-ocurrio)
      - [Prevenirlo o Evitarlo](#prevenirlo-o-evitarlo)
      - [Detectar y Recuperar](#detectar-y-recuperar)
- [Practica Semaforos para los Procesos](#practica-semaforos-para-los-procesos)
- [üß† M√≥dulo 5: Administraci√≥n de Memoria](#-m√≥dulo-5-administraci√≥n-de-memoria)
  - [Funciones y Operaciones](#funciones-y-operaciones)
    - [üîç Consideraciones Generales](#-consideraciones-generales)
    - [üó∫Ô∏è Espacio de Direccionamiento](#Ô∏è-espacio-de-direccionamiento)
    - [‚öôÔ∏è Hardware: MMU (Memory Management Unit)](#Ô∏è-hardware-mmu-memory-management-unit)
    - [‚öôÔ∏è Hardware: Cach√©](#Ô∏è-hardware-cach√©)
    - [Como se maneja el Espacio de Memoria de un Proceso](#como-se-maneja-el-espacio-de-memoria-de-un-proceso)
    - [Como se manejan las Direcciones](#como-se-manejan-las-direcciones)
      - [üß± 1. En Tiempo de Compilaci√≥n](#-1-en-tiempo-de-compilaci√≥n)
      - [üì¶ 2. En Tiempo de Carga](#-2-en-tiempo-de-carga)
      - [üîÅ 3. En Tiempo de Ejecuci√≥n](#-3-en-tiempo-de-ejecuci√≥n)
  - [Asignaci√≥n de Memoria Contigua](#asignaci√≥n-de-memoria-contigua)
    - [Sistema Monoprogramado (Unica Partici√≥n)](#sistema-monoprogramado-unica-partici√≥n)
    - [Particiones Fijas](#particiones-fijas)
    - [Particiones Variables](#particiones-variables)
    - [üìä Tabla Comparativa de Esquemas de Asignaci√≥n de Memoria Contigua](#-tabla-comparativa-de-esquemas-de-asignaci√≥n-de-memoria-contigua)
    - [Segmentaci√≥n](#segmentaci√≥n)
      - [Definici√≥n](#definici√≥n-7)
      - [üìå Caracter√≠sticas](#-caracter√≠sticas)
      - [üõ† ¬øC√≥mo se administra?](#-c√≥mo-se-administra)
      - [‚úÖ Ejemplo pr√°ctico](#-ejemplo-pr√°ctico)
    - [Paginaci√≥n](#paginaci√≥n)
      - [Definici√≥n](#definici√≥n-8)
    - [‚öôÔ∏è ¬øC√≥mo funciona?](#Ô∏è-c√≥mo-funciona)
      - [Caracteristicas](#caracteristicas-2)
      - [‚ö°Ô∏è Optimizaci√≥n: TLB (Translation Lookaside Buffer)](#Ô∏è-optimizaci√≥n-tlb-translation-lookaside-buffer)
      - [Paginaci√≥n Multinivel](#paginaci√≥n-multinivel)
      - [Memoria Compartida](#memoria-compartida)
  - [Memoria Virtual](#memoria-virtual)
    - [Definici√≥n](#definici√≥n-9)
    - [Swapping](#swapping)
    - [Paginaci√≥n bajo demanda](#paginaci√≥n-bajo-demanda)
    - [Protocolo al Tener Fallo de p√°gina](#protocolo-al-tener-fallo-de-p√°gina)
    - [Calcular Rendimiento](#calcular-rendimiento)
    - [Reemplazo de p√°ginas](#reemplazo-de-p√°ginas)
      - [Primero en entrar, primero en salir - FIFO](#primero-en-entrar-primero-en-salir---fifo)
      - [Reemplazo de P√°ginas √≥ptimo - OPT](#reemplazo-de-p√°ginas-√≥ptimo---opt)
      - [Menos recientemente utilizado - LRU](#menos-recientemente-utilizado---lru)
      - [M√°s frecuentemente utilizada (MFU) / Menos frecuentemente utilizada (LFU)](#m√°s-frecuentemente-utilizada-mfu--menos-frecuentemente-utilizada-lfu)
      - [Bit de Referencia](#bit-de-referencia)
      - [Columna de Referencia](#columna-de-referencia)
      - [Segunda Oportunidad](#segunda-oportunidad)
      - [Segunda Oportunidad Mejorada](#segunda-oportunidad-mejorada)
    - [Como Asignar Frames a los Procesos](#como-asignar-frames-a-los-procesos)
      - [Algoritmos de reemplazo de P√°ginas](#algoritmos-de-reemplazo-de-p√°ginas)
    - [Hiperpaginaci√≥n](#hiperpaginaci√≥n)
  - [Sistemas Mixtos (Segmentaci√≥n con Paginaci√≥n)](#sistemas-mixtos-segmentaci√≥n-con-paginaci√≥n)
    - [Definici√≥n](#definici√≥n-10)
    - [Funcionamiento](#funcionamiento)
    - [Ventajas y Desventajas](#ventajas-y-desventajas)

# Modulo 1: Introducci√≥n a los Sistemas Operativos

## ¬øQue es un sistema operativo?

Definiciones dadas por el profesor sobre s.o:

> Conjunto de m√≥dulos o funciones (software), que, instalados en la computadora, se ocupan de controlar y administrar la ejecuci√≥n de los programas sobre los recursos que brinda el equipo (hardware), tales como: memoria, procesador, perif√©ricos, etc.

> Conjunto de programas que ordenadamente relacionados entre s√≠, contribuyen a que la computadora lleve a cabo correctamente su trabajo para nosotros en un ambiente dado.

El **kernel** es el n√∫cleo del sistema operativo. Es la parte m√°s importante, encargada de: administrar hardware,

### ¬øPor qu√© estudiar los sistemas operatiovs?

No s√≥lo en comprender los mecanismos de los mismos. Si no, entenderlos para evitar los errores m√°s comunes al programar o aumentar la seguridad del sistema operativo.

## Funciones y Objetivos

El sistema operativo es el √∫nico programa que interactua directamente con el hardware. Sus funciones primarias son:

### Inicializaci√≥n (proceso de arranque)

![inicializacion](/imgs/clase-1/inicializador.png)

Al encender una computadora, se ejecuta un **chequeo inicial**, controlado por el firmware de la placa madre, ya sea **_BIOS_** o **_UEFI_**. Este proceso se encarga de inicializar y verificar el hardware esencial (como la memoria RAM, el procesador y los discos). Adem√°s, permite al usuario acceder a una interfaz de configuraci√≥n, donde puede definir opciones como el orden de arranque.

Una vez completado este chequeo, el BIOS o UEFI busca un **dispositivo de almacenamiento** que contenga un **_MBR (Master Boot Record)_** v√°lido. Este MBR se encuentra en el **primer sector f√≠sico del disco** (sector 0). En √©l se almacena una peque√±a parte del **c√≥digo de arranque**.

El BIOS transfiere el control al c√≥digo ubicado en el MBR, el cual se encarga de identificar la **_partici√≥n activa_**, es decir, aquella que est√° marcada como booteable. Desde all√≠, el MBR accede al sector de arranque de dicha partici√≥n, donde se encuentra un puntero que lo dirige al **_gestor de arranque_** o **_bootloader_**.

El **_bootloader_** es un programa almacenado dentro del sistema de archivos del disco. Su funci√≥n es **cargar el n√∫cleo del sistema operativo (kernel)** en la **memoria RAM** y dar inicio a la ejecuci√≥n del sistema, dejando el entorno preparado para que el usuario comience a trabajar.

### Maquina Extendida (Interfaz)

Procedimiento que permite la interacci√≥n del usuario con el ordenador. Sus principales funciones:

-   Facilita comunicaci√≥n con el usuario
-   Aceptar entradas de nuevos trabajos
-   Abstracci√≥n: los programas no deben preocuparse de los detalles de acceso a hardware o de la configuraci√≥n

Existen diferentes clasificaci√≥n en las interfaces:

-   GUI (Grafica para Usuarios) -> KDE, Gnome, Aero
-   CLI (Linea de Comandos) -> Bash, cmd, powershell
-   NUI (Interfaz superior a la grafica) -> tactil, voz, gestos

### Administraci√≥n de recursos

-   Mas del 70% del s.o esta dedicado a esta funci√≥n
-   Gestiona politicas de asignaci√≥n de recursos para que los programas no compitan por los ellos
-   Optimiza los recursos

### Aislamiento

En un sistema multiusuario y multitarea, cada proceso y cada usuario no tendra que preocuparse por otros que esten usando el mismo sistema.

### Seguridad

Garantizar la integridad de los recursos y procesos como, tambien validar los usuarios del sistema. Existen 2 modos para lograrlo:

-   Modo dual de ejecuci√≥n del procesador - > separa en 2 tipos de instrucciones
    -   Modo usuario o no privilegiado
    -   Mood kernel o privilegiado (uso exclusivo para el s.o)
-   Juego de instrucciones diferenciadas del procesador

Si un usuario quiere usar instrucciones de kernel entra en un trap.

La seguridad se basa en 3 caracteristicas:

-   **Abstracci√≥n** -> Un usuario no puede escribir directo en el disco, su acceso debe estar limitado a la interfaz
-   **Administrar Recuersos** -> Politica de asignaci√≥n de recursos
-   **Aislamiento** -> Si el S.O ofrece separaci√≥n entre los datros, procesos y recursos de distintos usuarios. Ninguno debe tener acceso a la informaci√≥n del projimo.

## Clasificaciones de Sistemas Operativos

### Segun la Cantidad de Usuarios

-   **Monousuario** -> Un solo usuario
-   **Multiusuario** -> Varios usuarios (incluyendo remeto)

### Segun la Cantidad de Procesadores que Soporta

-   **Uniprocesador** -> Solo puede manejar un procesador de la computadora. Por lo que si tiene mas de un nucleo el cpu, es inutil.
-   **Multiprocesador** -> Sistemas capaces de manejar mas de un procesador

### Segun la Cantidad de Tareas que Sucesivas

-   **Monoprogramado o monotarea** -> Solo se puede ejecutar un proceso a la vez recien cuando finalize uno, arranca el siguiente.
-   **Multiprogramado(multitarea)** -> Mas de un proceso ejecutando el sistema

### Segun sus Aplicaciones (Usos)

-   **Proposito general** -> Propositos de amplia gama con cualquier fin
-   **Proposito especial** -> construccion a medida para un uso especifico. Se clasifica en:
    -   Tiempo real -> Tiempo de respuesta a eventos
        -   Tiempo Real No Cr√≠tico -> El tiempo de respuesta es importante, pero no vital
        -   Tiempo Real Cr√≠tico -> Requiere una respuesta inmediata
    -   Tolerante a fallas -> Se utilizan en aplicaciones donde es fundamental mantener un servicio continuo, incluso ante fallos de hardware o software. El mismo S.O detecta y corrige errores.
    -   Sistemas virtuales -> Los Sistemas Operativos Virtuales son capaces de administrar y gestionar otros sistemas operativos que se ejecutan de forma concurrente sobre el mismo hardware.

### Segun la Organizaci√≥n de su Arquitectura

Existen 2 formas principales de organizaci√≥n del n√∫cleo de un sistema operativo, junto a un enfoque h√≠brido:

-   **Monoliticos**

Todo el sistema operativo corre como un √∫nico proceso privilegiado que opera como supervisor. Todas las funcionalidades (gesti√≥n de memoria, archivos, dispositivos, etc.) est√°n integradas directamente en el n√∫cleo.

Ventajas:

-   Simplifica gran cantidad de mecanismos -> mayor velocidad ejecuci√≥n
-   Mayor flexibilidad

![monolitico](imgs/clase-1/monolitico.png)

-   **MicroKernel**

El n√∫cleo se mantiene en el minimo posible de funcionalidad, descargando en procesos especiales sin privilegios las tareas que implementan el acceso a dispositivos y las diversas politicas de uso del sistema. Se limita a las funciones m√°s b√°sicas (como planificaci√≥n y comunicaci√≥n).

Ventajas:

-   Esquema logico mas limpio
-   Implementaciones mas elegantes y faciles de comprender
-   Puede auto-repararse

![microkernel](imgs/clase-1/microkernel.png)

-   **Hibridos**

Sistemas que son mayormente monolitocs pero que manejan algunos procesos que parecerian centrales mediante de procesos de nivel de usuario como microkernel.

La mayor√≠a de los S.O. modernos, como Windows, adoptan este modelo por su equilibrio entre rendimiento y flexibilidad.

![hibrido](imgs/clase-1/hibrido.png)

## Interrupciones

### Definici√≥n

Cuando ocurra alg√∫n evento que requiere la atenci√≥n del sistema operativo, el mismo levanta la solicitud y detiene el proceso que estaba siendo ejecutado. El S.O ejecuta su rutina de manejo de interrupciones y atiende la interrupci√≥n. Las mismas se pueden organizar por orden de prioridad y hay un numero limitado.

### Clasificaci√≥n

#### Segun prioridad

-   **No Enmascarable (no postergar)** -> Debe ser atentido si o si en el momento
-   **Enmascarable (postergar)** -> No es urgente y se atiende cuando quiere

#### Segun su origen

-   **Software** -> llamadas del sistema (syscalls)
-   **Harware** -> llamadas por un componente fisico. Se subdivide en:
    -   Interno -> Dentro del procesador. Ejemplo: division por cero, acceso no autorizado a memoria.
    -   Externo -> Fuera del procesador. Ejemplo: ingreso por teclado, un pendrive co

### Diferencia Interrupci√≥n y Excepci√≥n

-   **Interrupci√≥n** -> Causas externas a la computadora
-   **Excepci√≥n** -> Causado por un proceso interno

### Funciones y Objetivos

-   **Administrar el hawrdawre manejando interrupciones**
-   **Abstraer las Interrupciones** -> Oculta al programa de usuario que ocurren interrupociones de hardware. Pero, avisa al usuario mediante mensajes, se√±ales o deteniendo el proceso.
-   **Atender Excepciones y Fallas** -> Durante la ejecuci√≥n de un programa, ocurre situaciones an√≥males
-   **Punto de entrada al Sistema Operativo** -> Medio por el cual un proceso realiza una llamada al sistema (ecall de Assembly). Estas llamadas sirven para:
    -   **Control de Procesos** -> crear o finalizar proceso, asignar o liberar memoria, etc...
    -   **Manipular Archivos** -> Crear, borrar o renombrar un archivo
    -   **Manipulaci√≥n de Dispositivos** -> Solicitar o liberar un dispositiovo
    -   **Manipular Informaci√≥n** -> Obtener o modificar la hora del sistema, pedir detalles acerca de procesos o archivos
    -   **Comunicaciones** -> Establecer una comunicaci√≥n con determinado proceso (local o remoto)
    -   **Protecci√≥n** -> Consultar o modificar la informaci√≥n relativa al acceso de objetos en el disco o sesi√≥n del usuario.

Las llamadas al sistema son expuestas al programador mediante las _interfaces de apliacaci√≥n al programador_(API).

## Modos de Ejecucion de los Procesos

![](/imgs/clase-1/ejecucion-programacion.png)

-   **Procesos Secuenciales** -> Cada proceso se ejecuta a continuaci√≥n del otro
-   **Multiprogramaci√≥n** -> Ilusion que se ejecutan varios procesos al mismo tiempo, pero en realidad esta alternando entre los diversos procesos que compiten por su atenci√≥n. Por lo que, atiende simultaneamente diversos procesos.
-   **Multiprocesamiento** -> Entorno donde hay mas de un procesador (CPU). Por lo que diferentes procesos independientes se ejecutan en paralelo.
    -   **Asim√©trico** -> Procesadores con arquitecturas distintas. Tambien se pueden llamar como coprocesaodres o procesadores coadyuvantes.
    -   **Sim√©trico** -> Todos los CPU son iguales y pueden realizar en el mismo tiempo las operaciones
        -   Unifrm Memory Access(UMA) -> Ambos procesadores comparten la memoria, utilizan un BUS compartido
        -   Non-Uniform Memory Access(NUMA) -> Cada procesador tiene bancos de memoria. Da como ventajas que es mas rapido.
-   **Hibrido** -> Multiprogramaci√≥n y Multiprocesamiento se combinan. Las mayorias de PC funcionan asi.

## Definiciones Computo Distribuido

Proceso de c√≥mputo realizado entre computadoras independientes, o tambien dicho, entre procesadores que no comparten memoria. Hay diferentes implementaciones:

-   **C√∫mulos(Clusters)** -> Computadoras conectadas por una red local. La red es administrado por un software.
-   **Mallas (Grids)** -> Computadoras distribuidas a nivel geografico e interconectadas a una red.
-   **C√≥mputo En la Nube** -> Tercerizaci√≥n de servicios; la implementaci√≥n de servicios deja de ser relevante. Se aplica conceptos como:
    -   Servicios Web
    -   Software como Servicio
    -   Plataforma como Servicio
    -   Infraestructura como Servicio

# Modulo 2: De Programas a Procesos

## Conceptos Basicos

-   **¬øQue es un Programa?**

> Conjunto de instrucciones que resuelven un problema

-   **¬øQue es una Instrucci√≥n?**

> Unidad de ejecuci√≥n que dura un tiempo finito y se ejecuta sobre un procesador. No se descompone ni interrumpe

-   **¬øQue es un Proceso?**

> Porcion de un programa cargando en memoria central al cual se le asocia su contexto de ejecucion (run time environment) mediante una estructura de datos llamada vector de estado o **Bloque de Control del Proceso (PCB)**

Esa es la definici√≥n dada por los docentes, la que esta en el libro se define como:

> Un _proceso_ es la imagen en memoria de un programa, junto con la informaci√≥n relacionada con el estado de su ejecuci√≥n

## Entidad Pasiva y Activa

-   **Entidad Pasiva**

No cambia por si mismo, no tiene actividad propia, solo es un conjunto de instrucciones a ser esperado. Ejemplo: Un **programa** almacenado en disco o memoria.

-   **Entidad Activa**

Cambia de estado mientras se ejecuta, tiene actividad propia (consume CPU, E/S y memoria). Ejemplo: Un **proceso** en ejecucion

## Compilaci√≥n y Carga de un Proceso

![](/imgs/clase-2/Compilaci√≥n%20y%20Carga%20de%20un%20Proceso.png)

1. **Primer Paso: Traduccion de codigo fuente a maquina**
    1. Se parte de un programa fuente, donde escribimos el c√≥digo en un lenguaje de alto nivel.
    2. Se compila y entrega:
        - Area de texto: Instrucciones traducidas a codigo maquina
        - Tabla de Simbolos: Asocia las variables del programa a direcciones de memoria relativas al origen. Guarda:
            - Nombre del simbolo o identificador (nombre variable)
            - Direccion inicio variable
            - Direccion fin Variable
    3. El **Programa Objeto** es el resultado. Archivo binario con instrucciones pero sin estar listo para ejecutarse.
2. **Segundo Paso: Link-Editor (enlazador) Resuelve referencias externas del programa objeto para transformarlo a programa ejecutable**
    1. El link-editor labura sobre el programa objeto:
        - Incluye librerias
        - Combina todos los programas objetos en uno solo
        - Ajusta las direcciones de memoria, asignando identificadores √∫nicos a las variables y funciones.
    2. Da como resultado un programa ejecutable preparador para ser cargado a memoria.
3. **Tercer Paso: Ubica el programa ejecutable a memoria**
    1. Lee el archivo ejecutable
    2. Lo ubica en una posici√≥n libre de la memoria principal.
    3. Genera el PCB (Process Control Block); Estructura que almacenar√° toda la informaci√≥n necesaria para administrar el proceso(estado, registros, contador de programa, etc.).
4. **Cuarto Paso: Proceso en estado de ejecutarse**

## Procesos y Thread

-   **Procesos**
    Un proceso se define como la imagen de un programa en ejecucion; en memoria usando la CPU. A esta altura, un proceso tiene un espacio de direcciones de memoria, una pila, regitros y program counter (PC)

-   **Hilo(thread) o Proceso Liviano**
    Dentro de un proceso se puede tener secciones que tienen sus propios procesos, osea su propio espacio de memoria, registros, pila y program counter. Puede compartir memoria con el resto de thread que forman parte del mismo proceso.

## Administraci√≥n de Procesos

### Estructura Memoria CPU

![](/imgs/clase-2/memoria-cpu.png)

1. **Stack(pila):** √Årea utilizado para almacenar informaci√≥n asociada a la ejecuci√≥n de funciones. Ejemplo: Variables locales, parametros funciones, direcciones retorno
2. **Dynamic Data(heap):** Almacena datos de tama√±o variable o datos que se crean din√°micamente en tiempo de ejecuci√≥n. Ejemplo: malloc, realloc, free
3. **Static Data:** Datos de longitud fija creador en tiempo de compilacion. Ejemplo: variables globales y constantes
4. **Literales:** Area de texto para datos constantes. Ejemplo: "Hola"
5. **Instrucciones:** Area de texto donde guarda instrucciones del programa. Solo de lectura

### Bloque de Control (PCB)

Los datos de **cada** proceso se guardan en un PCB propio. Este, se almacena en la pila del procesador. Del stack se copia una imagen del proceso que se carga al CPU y se ejecuta.

En el PCB se guarda para cada proceso, la informaci√≥n necesaria para reanurlo en caso que sea suspendido o desalojado. A esto se le llama cambio de contexto.

### Cambio de Contexto y Proceso

-   **Cambio de Contexto**

Mecanismo mediante el cual el Sistema Operativo guarda el estado actual de la CPU (registros, contador de programa, etc.) asociado al proceso en ejecuci√≥n, para luego cargar el estado de otro proceso que debe ejecutarse

El cambio de contexto permite interrumpir un proceso y continuarlo m√°s adelante desde el mismo punto donde qued√≥.

-   **Cambio de Proceso**

Ocurre cuando el Sistema Operativo decide suspender el proceso actual y darle la CPU a otro proceso diferenteo. El cambio se puede dar por distintos motivos, por ejemplo: Finalizaci√≥n de una tarea, Interrupciones del sistema.

Implica necesariamente hacer un cambio de contexto: primero se guarda el estado del proceso que se suspende y luego se carga el estado del nuevo proceso.

-   **Diferencia**

| Concepto               | ¬øQu√© hace?                                         | ¬øCu√°ndo ocurre?                                                                            |
| ---------------------- | -------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| **Cambio de Contexto** | Guarda el estado de un proceso y carga el de otro. | Cada vez que se cambia el proceso en ejecuci√≥n.                                            |
| **Cambio de Proceso**  | Elige otro proceso para ejecutar.                  | Cuando el sistema operativo lo decide (fin de proceso, interrupci√≥n, planificaci√≥n, etc.). |

### Objetivos del PCB

-   Localizaci√≥n de la informaci√≥n sobre el proceso por parte del S.O
-   Mantener registrados los datos del proceso en caso de suspender la ejecuci√≥n

### Contenido del PCB

-   **Estado Actual del Proceso**
-   **Contador de Programa**: Cu√°l es la siguiente instrucci√≥n a ser ejecutada por el proceso
-   **Registros del CPU**: Debe ser respaldada y restaurada cuando se registra un cambio de estado
-   **Informaci√≥n de Planificaci√≥n(scheduling)**: Prioridad del proceso, cola que tiene agendada
-   **Informaci√≥n de Administraci√≥n de Memoria**: Informaci√≥n de mapeo de memoria
-   **Informaci√≥n de Contabilidad**: Informaci√≥n de la utilizaci√≥n de recursos que ha tenido este proceso
-   **Estado de E/S**: Listado de dispositivos y archivos asignados que el proceso tiene abiertos en un momento dado

Muchos de estos temas seran vistos a futuro.

## Transici√≥n de Estados de un Proceso

### Tipos de Estados

Un proceso puede transitar por varios estados a lo largo de su vida dentro del sistema operativo:

-   **Nuevo (New):** Se solicit√≥ al sistema operativo la creaci√≥n de un proceso, y sus recursos y estructuras est√°n siendo creadas (PCB). Ejemplo: Se abre un programa

-   **Listo (Ready):** El proceso ya est√° preparado para ejecutarse, pero todav√≠a no se le ha asignado un procesador. Permanece en espera en la cola de procesos listos. Ejemplo: El programa ya esta cargado en memoria

-   **En Ejecuci√≥n (Running):** El proceso est√° siendo ejecutado en este momento. El programa se empieza a ejecutar y se puede utilizar. Ejemplo: El programa empieza a ejecutarse y el usuario puede utilizarlo.

-   **Bloqueado (Blocked):** El proceso no puede avanzar porque est√° esperando a que ocurra alg√∫n evento (como la finalizaci√≥n de una operaci√≥n de entrada/salida). Aunque haya un procesador disponible. El programa espera que el disco duro termine de abrir un archivo. Ejemplo: el programa espera que el disco duro termine de abrir un archivo.

-   **Zombie:** El proceso ha finalizado su ejecuci√≥n, pero el sistema operativo debe realizar ciertas operaciones de limpieza para poder eliminarlo de la lista. Ejemplo: El programa termin√≥ su ejecuci√≥n, pero su informaci√≥n a√∫n debe ser recolectada por el sistema operativo.

-   **Terminado (Exit):** El proceso termin√≥ de ejecutarse; sus estructuras est√°n a la espera de ser limpiadas por el sistema operativo. Ejemplo: Finalmente, el sistema elimina toda la memoria, PCB, y otros recursos asociados al programa.

### Diagrama de Proceso

Un proceso puede pasar varias etapas diferentes en el sistema operativo, y el modelo depende del mismo. Hay varios modelos, pero el mas generico es el siguiente:

![](/imgs/clase-2/Modelo%20Generico%20Estados.png)

#### Modelo 7 Estados

![](/imgs/clase-2/Modelo%207%20estados.png)

Se crea un nuevo proceso que debe ser admitido, este se puede poner en listo o en listo/suspendido (esperando memoria). Cuando esta listo, esta esperando que el S.O le otorgue el CPU para ponerlo en ejecuci√≥n. Cuando se encuentra en ejecuci√≥n pueden pasar 2 cosas, finaliza o se bloquea por una interrupci√≥n

#### Modelo 5 Estados

![](/imgs/clase-2/Modelo%205%20Estados.png)

Modelo mas sencillo, no existe los estados de listo/suspendido o bloqueado/suspendido

### Colas

Una cola es una estructura de datos donde los elementos se agregan al final y se sacan del principio. El primero que entra es el primero que sale.

Aplicado a procesos, una cola es donde se organizan los procesos que est√°n esperando. Por ejemplo:

-   Cuando un proceso pasa al estado Listo, se pone en la cola de Listos.
-   Cuando un proceso est√° esperando por I/O, se pone en la cola de Bloqueados.

Todos los estados son de tipo cola, excepto los de ejecuci√≥n. Porque, el CPU solo puede ejecutar un proceso a la vez.

### Clasificaci√≥n Estados

-   **Estados Activos**

Son aquellos que compiten por el procesador o est√°n en condiciones de hacerlo. Estos son: ejecuci√≥n, listo y bloqueado (no pueden ejecutarse de momento por necesitar alg√∫n recurso ).

-   **Estados Inactivos**

Son aquellos que no pueden competir por el uso del procesador. Estos son suspendido/bloqueado y suspendido/listo.

### Razones de un Cambio de Estado de Proceso

-   Interrupciones de Hardware Externas
-   Excepci√≥n(trap)
-   Llamada al sistema operativo
-   Por finalizaci√≥n

## Creaci√≥n de Procesos

### Razones para crear un proceso

Todos los procesos son creados por el sistema operativo, aunque un proceso puede crear otro proceso. Hay 4 razones para crear uno:

-   La llegada de un trabajo nuevo al sistema.
-   Un proceso enviado por un usuario.
-   La necesidad de brindar un servicio a un programa en ejecuci√≥n.
-   La creaci√≥n expl√≠cita por parte de otro proceso existente.

### Tipos de Creacion de Procesos

Cuando un proceso crea a otro, el proceso creador se llama **padre** y el proceso generado se llama **hijo**. Estos procesos suelen **comunicarse** y **cooperar** entre s√≠.

-   Jerarquia: Cada proceso que se crea es hijo del proceso creador y hereda el entorno de ejecuci√≥n de su padre. Puede ser de 2 maneras:
    -   El padre continua ejecutando en paralelo con sus hijos
    -   El padre espera que todos sus hijos hayan terminado y luego sigue √©l.
-   No Jerarquica -> Se ejecutan de forma independiente

### Secuencia de creaci√≥n de un proceso

1. Asignar un identificador al nuevo proceso
2. Asignar espacio memoria para el proceso
3. Incializar la estructura de datos PCB
4. Establecer enlaces apropiados con otras estructuras del sistema operativo, como archivos abiertos, referencias a procesos padres, hijos o hermanos.
5. Ampliar o crear otra estructura de datos en caso que fuerza necesarios (archivos y de m√°s)

### Finalizar de un proceso

-   Desaparece el PCB
-   Liberar recursos comunes
-   Recursos locales son destruidos: Los datos como variables o memoria del stack

La **Terminaci√≥n en cascada** es cuando un proceso termina (muere) tambien deben terminar sus hijos.

## Hilos

### Definici√≥n

La simple transferencia de de memoria a el procesador con toda su planificaci√≥n, podr√≠a llevara un desperdicio burocratico (tiempo que se pierde en asuntos administrativos) de recursos, una respuesta este problema son los hilos.El concepto de **hilo** (tambi√©n llamados _threads_ o _procesos livianos_) ya fue mencionado anteriormente, pero realizamos un repaso:

> Dentro de un proceso pueden existir **secciones independientes** (hilos), cada una con su propio espacio de registros, pila y contador de programa. Sin embargo, **comparten el espacio de memoria** con los dem√°s hilos del mismo proceso.

### Caracteristicas

Cada hilo posee una estructura propia llamada **TCB** (_Thread Control Block_), que es similar al PCB de un proceso, pero contiene **menos informaci√≥n**, ya que muchos recursos son compartidos con los dem√°s hilos del mismo proceso.

Cada hilo incluye:

-   Un **TID** (Thread Identifier)
-   Un **program counter (PC)**
-   Un conjunto de **registros de CPU**
-   Una **pila** propia

Cada hilo se ejecuta de forma **secuencial**, aunque en sistemas **multiprocesadores** pueden ejecutarse **en paralelo**.

Todos los hilos de un mismo proceso comparten:

-   Un √∫nico **espacio de direccionamiento en memoria**
-   Los **archivos y dispositivos abiertos**
-   El uso de **relojes y otros recursos del sistema operativo**

Adem√°s, los hilos pueden **crear hilos hijos**, y est√°n dise√±ados para **cooperar entre s√≠** compartiendo los recursos mencionados.

### Ventajas respecto a los Procesos

-   Requiere **menos tiempo** realizar un cambio de contexto entre hilos que entre procesos.
-   **Comparten espacio de memoria** y recursos, permitiendo una comunicaci√≥n m√°s r√°pida entre ellos.

### Implementaci√≥n de Hilos

#### Hilos a Nivel de Usuario (ULT)

**Caracter√≠sticas:**

-   Administrados completamente por el **usuario** mediante una librer√≠a en la aplicaci√≥n.
-   Se crean en **tiempo de compilaci√≥n**.
-   El sistema operativo **no tiene conocimiento** de su existencia.
-   Todo el proceso se ve como una sola unidad para el sistema operativo.

**‚úÖ Ventajas:**

-   El cambio entre hilos es **r√°pido** y no requiere cambiar a modo kernel.
-   Compatible con **cualquier sistema operativo**
-   El algoritmo de planificaci√≥n puede ser **definido libremente** por el programador sin interferir con el planificador del sistema.
-   Se comparten memoria sin establecer mecanismos de comunicaci√≥n, por lo que es m√°s rapido

**‚ùå Desventajas:**

-   No aprovecha **multiprocesamiento real**: el kernel solo ejecuta un hilo del proceso a la vez.
-   Las **llamadas bloqueantes** afectan a **todos los hilos del proceso**.
-   Se puede usar una t√©cnica llamada **Jacketing** para transformar llamadas bloqueantes en no bloqueantes, pero esto **agrega sobrecarga** al sistema.

#### Hilos a Nivel de Kernel (KLT)

**Caracter√≠sticas:**

-   Administrados directamente por el **kernel del sistema operativo**.
-   Son completamente visibles y controlables por el sistema operativo.

**‚úÖ Ventajas:**

-   Las rutinas del **kernel tambi√©n pueden ser multi-hilo**.
-   Si un hilo se bloquea, el kernel puede planificar otro hilo del mismo proceso.
-   Se puede ejecutar **m√∫ltiples hilos del mismo proceso en distintos procesadores**, logrando **paralelismo real**.
-   Aprovecha la comunicaci√≥n con el sistema operativo tanto para solicitar recursos como para gestion de recursos en ejecucion multiprocesador

**‚ùå Desventajas:**

-   El cambio de hilo requiere pasar a **modo kernel**, lo cual es m√°s costoso.
-   Tiene **mayor overhead** (sobrecarga) en tiempo y recursos del sistema operativo.
-   Se requiere utilizar librerias para implementarlo

### Estado de los Hilos

Los hilos pueden seguir los mismos estados que los procesos:

1. Listo(spawn)
2. Bloqueado
3. Ejecutando
4. Terminado

![](/imgs/clase-2/Estados%20Hilos.png)

### Patrones de Trabajo con Hilos

Se puede emplear m√°s de uno de estos patrones en diferentes √°reas de cada aplicaci√≥n

-   **Estructura Jefe/Trabajador**

Un hilo tiene una tarea distinta de todos los dem√°s: el hilo _jefe_ genera o recopila tareas para realizar, las separa y se las entrega a los hilos _trabajadores_

Recomendado para servidores (como apache) y aplicaciones graficas (GUI).

![](/imgs/clase-2/Hilos%20Estructura%20servidor%20trabajador.png)

-   **Estructura en Equipo de Trabajo**

Se crean muchos hilos id√©nticos, que realizar√°n las mismas tareas sobre diferentes datos. Todos los hilos son **equivalentes** y **procesan sus propias solicitudes** de manera aut√≥noma.

Recomendado para calculos matematicos.

![](/imgs/clase-2/Hilos%20estructura%20en%20equipo.png)

-   **Estructura de Entubamiento o linea de Ensablado(pipeline)**

El procesamiento de datos se realiza en **etapas**. Cada hilo puede enfocarse a hacer solo un paso y pasarlo los datos a otro hilo conforme vaya terminando. Todos los hilos cumplen tareas diferentes .Una de las ventajas es que ayuida a mantener rutinas simples de comprender, y permite que el procesamiento de datos continue, incluse si parte del programa est√° bloqueado.

Este modelo se asocia con el concepto de **Pipelining**, debido a la similitud en el flujo de datos.

![](/imgs/clase-2/Hilos%20Estructura%20Entubamiento.png)

## Fibra

### Definici√≥n

Una **fibra** es una unidad de ejecuci√≥n que debe ser **agendada manualmente** (`scheduler`) por la propia **aplicaci√≥n**.

-   Las fibras se ejecutan dentro del contexto de un hilo
-   Un mismo hilo puede agendar y administrar **varias fibras** simult√°neamente.

### Caracteristicas

-   Las fibras no son planificadas por el sistema operativo, sino que su **cambio de contexto es controlado por la aplicaci√≥n**.
-   Una fibra **no posee su propio hilo**: se ejecuta usando el hilo que la agenda.

### Ventajas

-   En general, **una fibra no presenta ventajas** sobre una aplicaci√≥n multi-hilo bien dise√±ada.
-   El uso de fibras puede **hacer m√°s flexible** a aplicaciones que fueron pensadas para **agendar sus propios hilos** de ejecuci√≥n.

# Modulo 3: Planificaci√≥n de Procesos

## Definici√≥n

La _planificaci√≥n de procesos_ se refiere a c√≥mo determina el sistema operativo el orden en que ir√° cediendo el uso del procesador a los procesos que lo vayan solicitando, y a las politicas que empleara para que el uso que den a dicho tiempo no sea excesivo respecto al usop esperado al sistema.

## Objetivos

-   **Ser justo:**¬†Debe tratarse de igual manera a todos los procesos que compartan las mismas caracter√≠sticas, y nunca postergar indefinidamente uno de ellos (inanici√≥n o starvation)
-   **Maximizar el rendimiento:**¬†Dar servicio a la mayor parte de procesos por unidad de tiempo.
-   **Ser predecible:** Un mismo trabajo debe tomar aproximadamente la misma cantidad de tiempo en completarse independientemente de la carga del sistema
-   **Minimizar la sobrecarga:** El tiempo que el algoritmo pierda en burocracia (`overhead`)¬†debe mantenerse al m√≠nimo, dado que eÃÅste es tiempo de procesamiento √∫til perdido
-   **Equilibrar el uso de recursos:** Favorecer a los procesos que empleen recursos subutilizados, penalizar a los que peleen por un recurso sobreutilizado causando contenci√≥n en el sistema
-   **Evitar la postergaci√≥n indefinida (`starvation`):** Aumentar la prioridad de los procesos maÃÅs viejos, para favorecer que alcancen a obtener alg√∫n recurso por el cual est√©n esperando
-   **Favorecer el uso esperado del sistema:** En un sistema con usuarios interactivos, darle prioridad a los procesos que sirvan a solicitudes iniciadas por los usuarios(aun a cambio de penalizar a los procesos de sistema).
-   **Dar Preferencia a los procesos que podrain causar bloqueo:** El proceso que esta ejecutando que puede causar un bloqueo, no los sacamos de encima rapido.
-   **Favorecer a los procesos con un comportamiento deseable:** Si un proceso causa mucha demora, se lo puede penalizar porque degrada el rendimiento del sistema
-   **Degradarse suavemente:** Tratar que no impacte la carga del proceso cuando este cerca del 100%; tratar de bajar la performance del sistema para que no afecte

## Tipos de Planificaci√≥n

-   **Largo Plazo:** Generacion de nuevos procesos largos
    -   Se ejecuta peri√≥dicamente una vez cada varios segundos, minutos u horas
    -   Decide que procesos seran iniciados
    -   Modelo en deshuso
-   **Mediano Plazo (scheduler):** Toma decisiones conforme los procesos entran y salen del estado bloqueado
    -   Decide que procesos bloquear y activar. Esto ocurre debido a que los procesos t√≠picamente se bloquean¬†por escasez de alg√∫n recurso.
-   **Corto Plazo (dispatcher):** Decide entre los procesos listos para ejecutar, cual activar
    -   Decide c√≥mo compartir momento a momento la CPU entre los procesos que la requieren
    -   Se ejecuta decenas de veces por segundo
    -   Se encarga de hacer el cambio de contexto
    -   Detiene aquellos que exceden su tiempo de procesador
    -   Ske busca una planificaci√≥n a dar un tratamiento preferente a los procesos cortos. Porque no los sacamos rapido de encima.
-   **Extra largo plazo**
    -   El administrador decide que tarea realizar
    -   Modelo en deshuso

## Relaci√≥n entre Tipos Planificadores y Estados de los Procesos

Los tipos de planificaci√≥n incluyen los estados de procesos que van a trabajar:

-   **Largo Plazo:** Se encarga de las transiciones de nuevo a listo
-   **Mediano Plazo:** Se encarga de las transiciones de ejecuci√≥n y bloqueado, y bloqueado y listo
-   **Corto Plazo:** Se encarga de las transiciones de listo y ejecuci√≥n. Ejemplo:
    -   Ejecutando -> bloqueado => Llamada al sistema operativo
    -   Ejecutando -> listos => Interrupci√≥n por quantum (tema proximo)
    -   Bloqueado -> listos => Interrupci√≥n de finalizaci√≥n de E/S
    -   Ejecutado -> Terminado => Exit()

## Tipos de procesos

-   **CPU Bound:** Orientado al uso del CPU; procesos que alternan entre r√°fagas y que realizan computo interno
-   **I/O Bound:** Orientado al uso de dispositivos externos; Procesos que realizan mas usos de entradas y salidas que del CPU
-   **Procesos Cortos:** Aquellos que son de tipo I/O Bound pero, cada tanto hace uso del CPU, y estan bloqueados esperando que se libera I/O

## Mediendo las respuestas

### Unidades de Medici√≥n

Se laburan con 2 unidades para saber cuanto van a tardar:

-   **Tick:**
    -   Unidad de tiempo m√≠nima en que el sistema operativo mide el paso del tiempo internamente.
    -   Cada Tick corresponde a una interrupci√≥n de reloj programada por el timer del sistema.
    -   Su duraci√≥n lo determina el timer del sistema. En linux el tick es de 1 milisegundo y en windows entre 10 y 15ms
-   **Quantum:**
    -   Tiempo m√°ximo que un proceso puede usar la CPU antes de ser interrumpido.
    -   En linux el quantum varia entre 10 y 200 ticks (10 y 200 ms) y en windows entre 2 y 12 ticks (10 y 180ms)

El Tick es como el "tic-tac" de un reloj muy r√°pido ‚è±Ô∏è. El Quantum es cu√°ntos "tic-tac" seguidos puede quedarse un proceso usando el CPU antes de ser interrumpido. Ejemplo:

| Proceso | Ticks | Llegada |
| ------- | ----- | ------- |
| A       | 7     | 0       |
| B       | 3     | 2       |
| C       | 12    | 6       |
| D       | 4     | 20      |

El cambio de contexto se realiza cada 2 ticks, y un Quantum es de 5 ticks con un ordenamiento de ronda. Se operan con 4 procesos:

![](/imgs/clase-2/ticks%20grafico.png)

### M√©tricas Utilizadas

Para un proceso _p_ que requiere de un tiempo _t_ de ejecuci√≥n:

-   **Tiempo de respuesta(T):** Tiempo total desde que empieza hasta que termina su ejecuci√≥n. Pero no esta en la cola de procesos, osea apartir desde que se le da el CPU.
-   **Tiempo Espera(E = T - t):** Tiempo total menos tiempo perdido; cuaÃÅnto tiempo _p_ estaÃÅ listo y esperando ejecutar.
-   **Proporci√≥n de Penalizaci√≥n(P = T/t):** Tiempo total sobre tiempop de espera. Proporci√≥n tiempo de respuesta en relaci√≥n al tiempo de uso del procesador.
-   **Proporci√≥n de Respuesta(R = t/T):** Inverso de P; fracci√≥n del tiempo de respuesta durante la cual _p_ pudo ejecutarse.
-   **Tiempo N√∫cleo o Kernel:** Tiempo que pasa el sistema en espacio de nucleo
-   **Tiempo de Sistema:** Espacio que pasa en una llamada al sistema
-   **Tiempo de Usuario:** Proceso en modo suario; ejecutando instrucciones que forman parte expl√≠cita y directamente del programa
-   **Tiempo de uso del Procesador:** Tiempo durante el cual el procesador ejecuto instrucciones por cuenta de un proceso(modo usuario o kernel).
-   **Tiempo desocupado (idle):** Tiempo en que la cola de procesos listos est√° vac√≠a y no puede realizarse ning√∫n trabajo
-   **Utilizaci√≥n CPU:** Porcentaje del tiempo en que el CPU realiza trabajo √∫til
-   **Valor Saturaci√≥n** Formula en funci√≥n de frecuencias de llegada al proceso(Œ±) y el tiempo de servicio requerido para resolverlo(Œ≤). Se define por la divisi√≥n _p_ = Œ±/Œ≤ si:
    -   _p_ = 0 => Nunca lelgan procesos nuevos (sistema desocupado)
    -   0 < _p_ < 1 =>
    -   _p_ = 1 => Los procesos se despachan al ritmo que van llegando
    -   _p_ > 1 => El sistema esta saturado

## Clasificaci√≥n Algoritmos de Planificaci√≥n

El planificador a corto plazo, se invoca por alguna de las 4 circustancias:

-   Ejecutado a Espera
-   Ejecutado a Listo
-   Espera a Listo
-   Ejecutando a Terminado

los algoritmos vistos se podr√≠an calificar seg√∫n dos criterios:

-   Sistemas Expropiativo, Cooperativo o Non-Non-Preemptive,(desusho) = El proceso cede voluntariamente el control de la CPU al sistema operativo
-   Sistema Apropiativos, No Cooperativo o Preemptive = El sistema operativo puede interrumpir al proceso en cualquier momento
-   No considera Informaci√≥n Intrinseca = No es necesario el historial de procesos o informaci√≥n de antemano para que el algoritmo funcione
-   Considera Informaci√≥n Intrinseca = Es necesario un historial de procesos como tiempo o tipo

| X           | No considera Informaci√≥n Intrinseca | Considera Informaci√≥n Intrinseca |
| ----------- | ----------------------------------- | -------------------------------- |
| Cooperativa | FSFS                                | SPN, HPRN                        |
| Preenvite   | RR                                  | PSPN, FB, SRR                    |

### Primero en Llegar, Primero Servido (FCFS) (Procesos Secuenciales)

Funciona como una cola de procesos; el primero en llegar, es el primero que atiendo. Es el algoritmo mas simple. Presenta caracteristicas:

-   Reduce al minimo la sobrecarga administrativa (overhead)
-   Si hay procesos largos, se vera afectado el rendimiento
-   Favorece los procesos largos
-   Este algoritmo da salida a todos los procesos siempre que¬†œÅ ‚â§ 1. Si¬†œÅ > 1 la demora en iniciar a los nuevos procesos aumentar√° cada vez produci√©ndose inanici√≥n
-   No requiere hardware de apoyo

Ejemplo:

![](/imgs/clase-2/Algoritmo%20FCFS.png)

### Round Robin (multiprogramaci√≥n)

Es como una combinaci√≥n al concepto de multiprogramaci√≥n y FCFS; Tiene tambien un mismo sistema de colas, la diferencia radica en que cada tantos _t_ tiks de un proceso, alterna por otro proceso. Caracteristicas:

-   Favorece a los procesos cortos
-   Reduce al minimo la sobrecarga administrativa (overhead)
-   Busca dar una relaci√≥n de respuesta buena para los procesos largos y cortos
-   Si un proceso no ha concluido dentro de su quantum se lo expulsar√° y ser√° puesto al final en la cola de listos donde deber√° esperar su¬†turno nuevamente
-   Los procesos que son despertados de estado de suspensi√≥n son tambi√©n puestos al final de la cola de listos
-   La ronda puede ser ajustada modificando la duracion de quantum. Conforme se incrementa quantum, mas se asemeja a FCFS.

![](</imgs/clase-2/Algoritmo%20Round%20Robin(1).png>)

![](</imgs/clase-2/Algoritmo%20Round%20Robin(2).png>)

### El Proceso m√°s Corto a Continuaci√≥n (SPN, Shortest Process Next)

Se ordenada la cola de listos de acuerdo al mas corto. Llega a ser mas justo que FCFS. El problema que tiene es saber la duraci√≥n del proceso, entonces lo que se haces es analizar ejecuciones anteriores. Presenta las caracteristicas:

-   Favorece a los procesos cortos
-   Mas justo que FCFS
-   Un proceso largo puede esperar mucho para su ejecuci√≥n

![](/imgs/clase-2/SPN.png)

Tambien se cuenta con **PSPN** (Apropiativo SPN) que incluso favorece a los procesos largos, combina las ideas de SPN con un esquema multitarea apropiativo

### El m√°s Penalizado a Continuaci√≥n (HPRN, Highest Penality Ratio Next)

Intenta situarse a un punto intermedio entre el FCFS (que favorece a los procesos largos) y SPN (que favorece a los cortos). Calcula un √≠ndice de penalizaci√≥n P para cada proceso que est√° en la cola:

```
P = (w+t)/t
```

Donde:

-   `w` = tiempo de espera del proceso
-   `t` = tiempo de CPU requerido

Elige el proceso con el mayor valor de P (el m√°s "penalizado" por el tiempo que lleva esperando).

Presenta las caracteristicas:

-   Cuando hay muchos procesos en cola, calcular P para todos puede generar overhead.
-   Ayuda a evitar inanicisi√≥n _p_ < 1
-   M√°s justo que SPN y FCFS.

Inanicisi√≥n: Ocurre cuando un proceso o hilo nunca consigue acceso a un recurso porque otros procesos siempre son priorizados sobre √©l.

### Ronda Egoista (SRR)

Es una variante del Round Robin que introduce una distinci√≥n entre 2 colas de procesos:

-   `Cola de procesos nuevos`
-   `Cola de procesos aceptados`

Mientras haya procesos aceptados listos, solo ellos compiten por la CPU. Los procesos nuevos esperan en procesos nuevos. Los procesos nuevos aumentan su prioridad mientras esperan. Cuando la prioridad de un proceso nuevo crece lo suficiente, se promueve a la cola de aceptados y empieza a competir.

Cuenta con los siguientes parametros:

-   `a`: Ritmo al que sube la prioridad de procesos nuevos.
-   `b`: Ritmo al que sube la prioridad de procesos aceptados.

Apartir del resultado dado por division b/a, se puede llegar a las siguientes conclusiones:

-   b/a = 0 => Se comporta como un Round Robin (todos los procesos compiten por igual)
-   b/a < 1 => Los procesos nuevos eventualmente seran aceptados
-   b/a >= 1 => Su comportamiento tiende a FCFS (los procesos nuevos pueden quedarse esperando mucho m√°s)

Presenta las siguientes caracteristicas:

-   Favorece a procesos que ya llevan tiempo ejecut√°ndose antes de aceptar procesos nuevos.
-   Mejora el rendimiento bajo alta carga

![](/imgs/clase-2/SRR.png)

### Algoritmos con M√∫ltiples Colas de Listos

Para poder entender el pr√≥ximo algoritmo (multilevel feedback), primero se analiza c√≥mo funciona t√≠picamente un sistema con m√∫ltiples colas de listos.

![](/imgs/clase-2/multiples%20colas.png)

Se definen m√∫ltiples colas, cada una con una prioridad. Se atienden s√≥lo los procesos de la cola de m√°s prioridad hasta que √©sta se vac√≠a. Luego se pasa a ejecutar los procesos de la cola siguiente.

### Retroalimentaci√≥n Multinivel (FB)

Existen varias colas de listos (por ejemplo, cola 0, cola 1, cola 2...), cada una con:

-   Diferente prioridad.
-   Diferente quantum

Cuando un proceso llega al sistema, entra en la cola de m√°s alta prioridad:

Presenta las siguientes caracteristicas:

-   Favorece a los procesos cortos y recien llegados
-   Penaliza a los procesos largos

Cuando un proceso llega al sistema, entra en la cola de mas alta prioridad. Puede ser vuelto al final de la fila si:

### Ronda Loteria (RR)

Se basa en un esquema de probabilidades (loteria con boletos) para escoger al proximo proceso a ejecutar. A cada proceso se le asigna uno o varios numeros de boletos, y cada boleto representa una oportunidad de jugar a la loter√≠a. Cada vez que el planificador tiene que elegir el siguiente proceso a poner en ejecuci√≥n, elige un n√∫mero al azar, y otorga el siguiente quantum al proceso que tenga el boleto ganador.

Las prioridades se representa al otorgarle a un proceso varios numeros de loterias, de esta manera, tiene mas chance de que salga como ganador.

Presenta las caracteristicas:

-   A pesar de ser sencillo, es muy justo tanto para procesos cortos como largos
-   Degradaci√≥n suave incluso en entornos saturados
-   Los procesos pueden cooperar entre si: Si B estuviera esperando un resultado de A, podria transferirle sus boletos para aumentar la prioridad

### Algoritmos H√≠bridos

Los algoritmos vistos anteriormente, pueden ser combinados:

-   **Algoritmo por Cola dentro de FB**

Al introducir varias colas, se abre la posibilidad de que cada una de ellas siga un esquema diferente. Por ejemplo: La de mayor prioridad puede ser PSPN y las de menor prioridad pueden ser SRR.

## Planificaci√≥n de Hilos

![](/imgs/clase-2/mapeo.png)

Para la planificaci√≥n de hilos depende de c√≥mo √©stos son mapeados a procesos desde el punto de vista del planificador. El mapeo es la forma en que los hilos se conectan a procesos o hilos del sistema operativo. Hay 3 modelos principales de mapeo:

-   **Muchos a Uno(N:1)**

    -   Muchos hilos son agrupados dentro de un mismo de un s√≥lo proceso.
    -   Los hilos de usuarios entran en esta categoria. Por lo que, los hilos son transparentes para el sistema operativo.
    -   Los hilos no aprovechan realmente el paralelismo, y todos los hilos pueden bloquearse cuando uno solo de ellos se bloquea.

-   **Uno a Uno(1:1)**

    -   Cada hilo se ejecuta como un proceso ligero.
    -   La informaci√≥n requerida es mucho menor que la de un proceso regular y aparte es mas rapido
    -   Los hilos comparten el espacio de memoria, descriptos de archivos y demas estructuras
    -   Permite el paralelismo; puede ejecutar cada hilo en un procesador distinto

-   **Muchos a Muchos(N:N)**
    -   Permite hilos unidos: cada hilo corresponde a un solo proceso ligero
    -   Permite hilos no unidos: Uno o m√°s hilos estanm mapeados a cada proceso ligero
    -   Proporciona ambas caracteristicas de N:1 y 1:1

## Planificaci√≥n Multiprocesador

Hasta ahora, el concepto de planificaci√≥n fue visto dado un solo procesador. Se manejan 2 enfoces para la planificaci√≥n multiprocesador:

-   Mantener una sola lista de procesos y distribuirlos a cada nucleo
-   Mantener una lista por cada procesador

Se puede optar por el esquema de una cola de procesos listos por nucleo. Sin embargo, esta en deshuso, por lo complicado de mantener la afinidad y restaria flexibilidad.

### Afinidad a Procesador

Despues de que un programa se ejecuto en el CPU, tendra parte de sus datos copiados en la cache. Si el despachador decidiera lanzarlo en un CPU que no comparte la cache, estos datos tendrian que ser invalidados para mantener la coherencia. Por lo que, para soluci√≥n este problema, se tiene la afinidad a procesador.

La afinidad a un procesador indica la preferencia de un proceso o hilo a ejecutarse en un determinado procesador. Puede ser:

-   **Afinidad Suave:** El proceso prefiere un procesador, pero puede moverse si es necesario.
-   **Afinidad Dura:** El proceso solo puede ejecutarse en un procesador espec√≠fico.

La afinidad dura funciona mejor en un entornoi NUMA (Non-Uniform Memory Access, Cada procesador tiene bancos de memoria)

### Balanceo de Cargas

El balanceo de cargas consiste en distribuir equitativamente el trabajo (procesos o hilos) entre todas las colas de procesos para que ninguno est√© sobrecargado mientras otros est√°n desocupados. El objetivo es evitar que unos procesadores est√©n saturados de trabajo mientras otros est√°n desocupados. Para aplicar esto, necesita que todos los nucleos compartan la misma memoria (multiprocesadores simetricos). Hay 2 estrategias para esto:

-   **Migraci√≥n Activa o por Empuje**: Peri√≥dicamente se ejecuta una tarea que analiza la ocupaci√≥n de los procesadores, y si la misma pasa de determinado umbral, migra el proceso de la cola de dicho procesador a la cola del procesador m√°s desocupado.
-   **Migraci√≥n Pasiva o por Jal√≥n**: Ocurre naturalmente cuando un proceso pasa al estado de Listo y el planificador elige asignarlo a otro procesador

# Practica Planificaci√≥n

## Modelo de Planificaci√≥n de Procesos - Diagrama de Gantt

### Definici√≥n

Un **Diagrama de Gantt** es una representaci√≥n **gr√°fica** que muestra c√≥mo se distribuye el trabajo de los procesos y tareas del sistema operativo a lo largo del tiempo. Permite visualizar la interacci√≥n entre:

-   El planificador del sistema operativo.
-   Los procesos de usuario.
-   Las operaciones de entrada/salida (E/S).
-   Las prioridades de los procesos.

### Utilidades del diagrama:

-   Ver qu√© proceso tiene el control de la CPU en cada instante.
-   Visualizar el orden de ejecuci√≥n y los cambios de estado.
-   Comprender el comportamiento de distintos algoritmos de planificaci√≥n (FCFS, SPN, RR...).
-   Calcular m√©tricas como:
    -   **Tiempo de espera**
    -   **Tiempo de retorno**
    -   **Tiempo de respuesta**

### Modelo de transici√≥n de estados de procesos

Se utiliza un grafo b√°sico con **5 transiciones**. Cada n√∫mero representa un tipo de cambio de estado del proceso. Las transiciones est√°n numeradas.

![](/imgs/clase-4/Grafo%205%20estados.png)

Se asigna un **tiempo estimado** a cada transici√≥n (para la pr√°ctica se usan valores fijos). Por ejemplo:

> **Operaciones: (2 a 5 son at√≥micas -> no se pueden interrumpir)**
>
> 1. Nuevos - Listos: 10u
> 2. Listos - Ejecutando: 10u
> 3. Ejecutando - Listos: 5u
> 4. Ejecutando - Bloqueados E / S: 5u
> 5. Bloqueados E / S - Listos: 5u
> 6. Ejecutando - Terminados: 15u

### Construcci√≥n

![](/imgs/clase-4/grantt%20ejemplo.png)

-   Cada **columna representa el tiempo**, generalmente en saltos de 5 unidades para mayor facilidad (0, 5, 10...).
-   Se construye de **izquierda a derecha** conforme avanza el tiempo.
-   Cada conjunto de **filas**, puede representa algo distinto:
    1. **Estados del proceso**: Cada celda, muestra el n√∫mero de transici√≥n del modelo de estados que se encuentra el proceso.
    2. **Tiempo de procesamiento**: Aqu√≠, es donde se ejecutando una vez que el estado de ejecutado (transici√≥n 2) se encuentra listo
    3. **Prioridad del proceso**: n√∫mero asignado (menor n√∫mero = mayor prioridad).
    4. **Unidad de tiempo**: Marca el avance de tiempo.
    5. **Interrupciones de E/S**: Se indica el proceso que genera la solicitud de E/S (por ejemplo, A o B). Tipos comunes: E/S de video, disco, teclado, etc...
-   **Datos Adicionales:** Debajo de las l√≠neas de tiempo se completa informaci√≥n adicional respecto al evento que gener√≥ una transici√≥n:
    -   **Interrupciones**
        -   Clasificaci√≥n:
            -   Hardware Interno -> _Esto es debido a un error, por lo que no se marca en el diagrama. Simplemente explota la computadora._
            -   Hardware Externo
            -   Software
        -   A qu√© est√°n relacinados:
            -   Solicitud E/S
            -   Fin de E/S
            -   Llegada de un proceso
            -   Fin de un Proceso
    -   **Evaluaci√≥n de Prioridades:** Si la prioridad de un proceso es mayor, igual o menor que otro, Ej: P(A) > P(B).

El sistema es un **mono-procesador**: solo un proceso puede estar ejecut√°ndose a la vez dentro del conjunto de "Estados de Proceso".

### Trazas y Rafagas

Una **traza** es la secuencia ordenada de acciones que un proceso realiza durante su vida √∫til (desde que se crea hasta que termina). Incluye ejecutar algo, realizar interrupciones, entre otras. Un proceso siempre comienza y termina con una traza.

Por ejemplo:

> -   Proceso A: Ejecuta 20u, disco 20u, ejecuta 5u y termina.
>
> -   Proceso B: Ejecuta 5u, video 10u, ejecuta 20u, video 20u, ejecuta 10u, video 30u, ejecuta 5u y termina.

Una **rafaga** es cada ejecuci√≥n de la traza. Por ejemplo, del proceso A se tiene la rafaga "Ejecuta 20u" y "Ejecuta 5u", las peticiones externas no lo son.

### Prioridades y PCP

El **PCP** es un proceso a corto plazo que nos ahorra un cambio de proceso al ser interrumpido por el quantum, guardando recursos y overhead. El PCP se utiliza cuando continuamos ejecutando el mismo proceso al momento de ser interrumpido por quantum. En caso contrario, que debamos realizar un cambio de proceso, se lo llama como **process switch**.

Las prioridades se eval√∫an con cada transici√≥n entrante a la cola de Listos. Osea, en la aparici√≥n de la transici√≥n 1, 3 o 5. En caso que ambas prioriodades sean iguales P(A) == P(B), nos podemos guiar bajo 2 criterios para decidir a cual seder el CPU:

-   Si **ninguno se estaba ejecutando** de ante-mano, se desempatan por FIFO, osea, el m√°s antiguo tiene prioridad.
-   Si **ya habia un proceso ejecutandose**, pero ambas tienen la misma prioridad. No importa, se sigue ejecutando el mismo por PCP.

### Parametros

-   Algoritmo de Planificaci√≥n de Jobs (opcional)
-   Algoritmo de Planificaci√≥n de procesos a corto plazo
    -   FIFO -> No se utiliza
    -   Round Robin
        -   Recibe el Quantum
    -   SPF -> No se utiliza
    -   Prioridades Simples
        -   N√∫mero de prioridad
        -   Se es con desalojo o no
    -   Prioridad Variable
        -   N√∫mero de prioridad inicial
        -   F√≥rmula de rec√°lca de la prioridad
        -   Si es con desalojo o no
    -   Variaci√≥n o mezclas

## Ejercicio 1

### Consigna:

![](/imgs/clase-4/Grafo%205%20estados.png)

> Un sistema utiliza un planificador por prioridades con desalojo y tiene dos canales de E/S, conectados a video y disco.
>
> En un determinado momento llega un proceso A (p = 10), y a las 25 unidades de tiempo llega el proceso B (p = 5). Estos procesos tienen las siguientes **trazas** de ejecuci√≥n:
>
> -   **Proceso A:** Ejecuta 20u, disco 20u, ejecuta 5u y termina.
> -   **Proceso B:** Ejecuta 5u, video 10u, ejecuta 20u, video 20u, ejecuta 10u, video 30u, ejecuta 5u y termina.
>
> **Operaciones: (2 a 5 son at√≥micas)**
>
> 1- Propuestos - Listos: 10u
>
> 2- Listos - Ejecutando: 10u
>
> 3- Ejecutando - Listos: 5u
>
> 4- Ejecutando - Bloqueados E/S: 5u
>
> 5- Bloqueados E/S - Listos: 5u
>
> 6- Ejecutando - Terminados: 15u

### Soluci√≥n final

![](/imgs/clase-4/Ejercicio1/Completo.png)

## Ejercicio 2

### Consigna

![](/imgs/clase-4/Grafo%205%20estados.png)

> Un sistema utiliza un algoritmo de planificaci√≥n Round Robin con un quantum (tiempo maximo para ejecutar) de 15u y prioridades variables con desalojo del procesador. Las prioridades se calculan como la prioridad original del proceso m√°s el tiempo de ejecuci√≥n del proceso dividido por 2. Es decir (p + (te/2)). A menor valor de este c√°lculo, mayor prioridad. El sistema tiene un canal selector de entrada/salida conectado a un disco y una pantalla.
>
> En un determinado momento llega un proceso A (p = 13), y a las 25 unidades de tiempo llega el proceso B (p=20). Estos procesos tienen las siguientes **trazas** de ejecuci√≥n:
>
> -   **Proceso A:** Ejecuta 10u, video 5u, ejecuta 10u, disco 30u, ejecuta 10u y termina.
> -   **Proceso B:** Ejecuta 5u, disco 15u, ejecuta 5u, disco 20u, ejecuta 20u y termina.
>
> **Operaciones: (2 a 5 son at√≥micas)**
>
> 1. Propuestos - Listos: 10u
> 2. Listos - Ejecutando: 10u
> 3. Ejecutando - Listos: 5u
> 4. Ejecutando - Bloqueados E / S: 5u
> 5. Bloqueados E / S - Listos: 5u
> 6. Ejecutando - Terminados: 15u
>
> Se pide: Realizar el diagrama temporal de procesamiento, indicando claramente los tiempos de ejecuci√≥n de los procesos, de las rutinas del sistema operativo; y en la misma hoja de la grilla las interrupciones que se producen para posibilitar cada cambio (con su clasificaci√≥n), los conflictos (en caso de existir) y cu√°l fue el criterio utilizado para su resoluci√≥n.

### Soluci√≥n Final

![](/imgs/clase-4/Ejercicio2/Completo.png)

## Ejercicio 3

### Consigna

> Un sistema operativo tiene una planificaci√≥n de largo plazo con algoritmo SJF (Shortest Job First) y una planificaci√≥n de corto plazo con algoritmo Round Robin con un quantum de 15u, con reevaluaci√≥n de prioridades din√°micas, las cuales se calculan como la prioridad inicial del proceso m√°s la mitad del tiempo de la √∫ltima r√°faga de ejecuci√≥n del mismo: (PI + Tr/2), a menor valor de este c√°lculo, mayor prioridad. Adem√°s, se cuentan con 1 disco y 1 monitor conectado a un canal selector.
>
> En un instante 0 llegan los procesos A (Prioridad 3) y el B (Prioridad 10) con la siguiente traza de ejecuci√≥n:
>
> -   **Proceso A:** Ejecuta 5u, lee de disco 10u, ejecuta 15u, realiza un fork (en el √∫ltimo instante de la r√°faga anterior, creando el proceso C con una prioridad de 4), ejecuta 5u, ejecuta un wait (esperando la finalizaci√≥n de su hijo), ejecuta 5u y finaliza.
> -   **Proceso B:** Ejecuta 15u, graba en disco 10u, ejecuta 5u, muestra por pantalla 10u, ejecuta 20u y finaliza.
> -   **Proceso C:** Ejecuta 20u, escribe en disco 25u, ejecuta 5u y finaliza, enviando una se√±al SIGCHLD al padre, avisando que termin√≥.
>
> **Operaciones: (2 a 5 son at√≥micas):**
>
> 1. Propuestos - Listos: 10u
> 2. Listos - Ejecutando: 10u
> 3. Ejecutando - Listos: 5u
> 4. Ejecutando ‚Äì Bloqueado: 5u
> 5. Bloqueado - Listos: 5u
> 6. Ejecutando ‚Äì Finalizado: 10u

### Soluci√≥n Final

![](/imgs/clase-4/Ejercicio3/Completo.png)

# Modulo 4: Sincronizaci√≥n y Comunicaci√≥n entre procesos

## ¬øPorque?

La comunicaci√≥n entre procesos es necesario porque entre ellos comparten la misma memoria y se deben poner de acuerdo para laburar juntos. El acceso a estos recursos compartidos generan problemas de uso y de comunicaci√≥n entre los procesos. Para resolver estos problemas de competencia entre procesos, se utilizan dos mecanismos:

-   **Sincronizaci√≥n:** Ordenamiento de las operaciones en el tiempo debido a las **condiciones de carrera** (velocidad de ver cual gana el acceso al recurso).
-   **Comunicaci√≥n:** Intercambio de Datos entre los procesos.

La comunicaci√≥n permite que los procesos cooperen entre s√≠ en la ejecuci√≥n de un objetivo global, mientras que la sincronizaci√≥n permite que un proceso contin√∫e su ejecuci√≥n despu√©s de la ocurrencia de un determinado evento.

## Problemas Concurrentes

Los programas se pueden clasificar en:

-   **Secuencial**: Especifica una secuencia de instrucciones que se ejecutan sobre un procesador que definimos como proceso o tarea.

-   **Concurrente**: Especifica dos o m√°s procesos secuenciales que pueden ejecutarse concurrentemente como tareas paralelas. Requiere mecanismos de sincronizac√≥n y comunicaci√≥n.

## Concurrencia

Concurrencia es la capacidad de un sistema para ejecutar varios procesos de manera aparentemente simult√°nea, intercalando su ejecuci√≥n en el tiempo. Como multiprogramaci√≥n.

No significa necesariamente que se ejecuten al mismo tiempo (eso ser√≠a paralelismo), sino que sus ejecuciones se entrelazan, avanzando parcialmente y compartiendo recursos como la CPU o la memoria.

Diferencia entre paralelismo y concurrencia:

| Concurrencia                              | Paralelismo                            |
| ----------------------------------------- | -------------------------------------- |
| Se ejecutan aparentemente al mismo tiempo | Se ejecutan realmente al mismo tiempo  |
| Puede ocurrir en una sola CPU             | Requiere m√∫ltiples CPUs o n√∫cleos      |
| Se logra por intercalado y planificaci√≥n  | Se logra por ejecuci√≥n simult√°nea real |

<!--
La concurrencia no se refiere a dos o m√°s eventos que ocurren a la vez sino a dos o m√°s eventos cuyo orden es no determinista, esto es, eventos acerca de los cuales no se puede predecir el orden relativo en que ocurrir√°n.

Si bien dos procesos (o tambi√©n dos hilos) completamente independientes entre s√≠ ejecut√°ndose simult√°neamente son concurrentes, nos ocuparemos principalmente de procesos cuya ejecuci√≥n est√° vinculada de alguna manera.
-->

## Grafos de Precedencia

Para analizar la concurrencia, se creo el grafo de presedencia.

Un grafo sin ciclos donde cada nodo representa una unica sentencia o un conjunto secuencial de instrucciones. Ejemplo:

Se tienen P procesos, instrucciones o hilos (cualquiera sea la unidad de ejecuci√≥n) que se encuentran conectados entre s√≠.

![](/imgs/clase-5/grafo.png)

-   P1 se tiene que ejecutar antes que P2, P5 o P4.
-   P7 se debe ejecutar despues de P3 y P6.
-   P6 se debe ejecutar despues que P4 y P5

As√≠ sucesivamente se van creando poco a poco un grafo que permite ver relaci√≥n entre los distintos elementos de la ejecuci√≥n paralela.

### Condiciones de Bernstein

Dos sentencias cualesquiera Si y Sj¬† pueden ejecutarse concurrentemente produciendo el mismo resultado que si se ejecutaran secuencialmente s√≠ s√≥lo s√≠ se cumplen las siguientes condiciones:

1. Read(Si) ‚à© WrIte(Sj) = (√∏)
2. WrIte(Si) ‚à© Read(Sj) = (√∏)
3. WrIte(Si) ‚à© WrIte(Sj) = (√∏)

Si las tres condiciones producen conjunto vac√≠o, podemos asegurar que no hay dependencia entre las sentencias.

## Especificaci√≥n Concurrente

### Instrucciones FORK y JOIN

-   **FORK** -> Se crean dos ramas (padre e hijo) que contin√∫an su ejecuci√≥n en concurrencia desde el mismo punto. Es el inicio de la concurrencia.
-   **JOIN** -> Lo ejecuta el proceso padre para indicar que espera a que el hijo termine antes de continuar.
-   **QUIT** -> Lo ejecuta el proceso hijo cuando termin√≥ su tarea.
-   **JOIN y QUIT** -> Recombina la concurrencia, une las 2 ramas, indicando que la concurrencia finalizo.
<!-- - **FORK ETIQUE** -> Produce dos ejecuciones concurrentes en un programa. -->

Ejemplo:

Programa para encontrar el m√°ximo entre 3 n√∫meros:

```py
cobegin
  m1 = max(a,b);
  m2 = max(c,d);
codend

m = max(m1,m2);
return m;
```

Su ejecici√≥n con FORK y JOIN:

```
FORK max1;
FORK max2;
join;
join;

max1:
  m1 = max(a,b);
  quit;

max2:
  m2 = max(c,d);
  quit;
```

## Algunos Conceptos

### Conceptos

-   **Operaci√≥n At√≥mica**: se ejecuta completamente o no se ejecuta en absoluto. Aunque el sistema pueda interrumpir el proceso que la ejecuta, no se ver√° un estado intermedio o parcial de esa operaci√≥n desde fuera.
-   **Race Condition**: Situaci√≥n cuando dos o m√°s procesos acceden y modifican un recurso compartido al mismo tiempo, y el resultado final depende del orden exacto de ejecuci√≥n de esas operaciones.
-   **Secci√≥n/Regi√≥n Cr√≠tica**: Es la parte del c√≥digo de un proceso donde se accede a recursos compartidos que pueden causar conflictos si son modificados por varios procesos a la vez. En esta secci√≥n es crucial garantizar que s√≥lo un proceso pueda ejecutarla a la vez.
-   **Recurso Compartido**: Un recurso compartido es cualquier elemento del sistema que puede ser accedido por m√∫ltiples procesos o hilos.
    -   **Puntos de Entrada**: Cantidad de procesos que pueden utilizarlo simultarneamente al mismo
    -   **Recurso Critico o No Compatible**: un recurso con 1 punto de entrada
-   **Mutua Exclusi√≥n**: Mecanismo que ordena los procesos para que accedan de forma ordena a un recurso, asegurando que solamente un proceso a la vez pueda ejecutar su secci√≥n cr√≠tica. Arregla la Race Condition.

## Regi√≥n Critica

El problema de la regi√≥n cr√≠tica consiste en sincronizar los procesos de forma tal que se cumpla el siguiente **procolo de sincronizaci√≥n**:

1. **Mutua Exclusi√≥n**: Mecanismo que ordena los procesos para que accedan de forma ordena a un recurso, asegurando que solamente un proceso a la vez pueda ejecutar su secci√≥n cr√≠tica. Arregla la Race Condition.
2. **Progreso**: El programa avance y no monopolize un recurso
3. **Espera Limitada**: Un proceso debe poder entrar a la regi√≥n critica despu√©s de un n√∫mero limitado de intentos
4. **Abandono (tiempo limitado)**: Debe dejar la regi√≥n critica en un tiempo limitado. Es una consecuencia del 3.
5. **Penalidad**: Un proceso no puede consumir tiempo de ejecuci√≥n mientras espera por un recurso
6. **Privilegio**: No debe haber ningun recurso privilegiado

Se tiene un protocolo de acceso a la region. Se utilizan 3 funciones:

-   EntradaRC() -> Se bloquea el acceso para otros procesos
-   UsarRecurso()
-   salidaRC()

![](/imgs/clase-5/utilizacion%20region%20critica.png)

Vamos a ver diferentes algoritmos para proteger la region critica

## Algoritmos para Proteger la Regi√≥n Critica

<!-- Algoritmo a Nivel de Software - Utilizar una Bandera -->

### 1. Algoritmo de Sincronizaci√≥n con Espera Activa

Se declara una variable (bandera) p√∫blica booleana para se√±alizar si un recurso esta libre o no:

-   `ocupada = 0` ‚Üí recurso libre.
-   `ocupada = 1` ‚Üí recurso ocupado.

Se tiene los siguientes conceptos:

-   **Espera activa** (busy waiting): el proceso **ocupa la CPU** mientras espera que el recurso se libere.
-   **Spinlock**: el algoritmo **gira en bucle**, comprobando constantemente si el recurso se liber√≥.

Ejemplo:

```c
entradaRC()
{
    // Espera activa: se queda en bucle mientras la variable 'ocupada' sea verdadera (1). El proceso est√° esperando que el recurso se libere (ocupada = 0).
    while(ocupada){ };
    // Una vez que sale del bucle, se marca el recurso como ocupado (entra a la regi√≥n cr√≠tica).
    ocupada = 1;
}

salidaRC()
{
    // Se libera el recurso: permite que otros procesos puedan entrar a la regi√≥n cr√≠tica.
    ocupada = 0;
}

```

‚ùå Problemas:

-   Desperdicio de CPU.
-   La variable ocupada es un recurso compartido, y su acceso no es at√≥mico.

### 2. Alternancia Estricta (Turnos)

Este algoritmo de sincronizaci√≥n permite que dos procesos se alternen el acceso a la regi√≥n cr√≠tica, asegurando que nunca entren al mismo tiempo. Se tiene 2 variables:

-   **i**: Identificador del proceso, puede ser 0 o 1 (por ejemplo, 0 para P0, 1 para P1).
-   **turno**: Variable global que indica cu√°l proceso tiene el turno para entrar.

Se realiza una comparaci√≥n de ambos:

-   Si **turno == i** => el proceso i puede entrar a la regi√≥n cr√≠tica.
-   Si **turno != i** => el proceso debe esperar activamente.

```C
entradaRC(int i)
{
    // Solo entra si es su turno.
    // Espera activa: se queda aqu√≠ mientras no sea su turno
    while(turno != i){ };

}

salidaRC(int i)
{
    // Cambia el turno para que le toque al otro proceso.
    // Si i = 0, lo pasa a 1; si i = 1, lo pasa a 0.
    turno = 1 - i;
}

```

‚ùå Problemas:

-   Solo se puede utilizar con 2 procesos
-   Puede generar inanici√≥n si no se libera el recurso

<!-- ### Algoritmo a Nivel de Hardware -->

### 3. Instrucciones At√≥micas de Hardware

Usar la instrucci√≥n tsl (Test and Set Lock), simula una operaci√≥n at√≥mica que verifica y bloquea el recurso si est√° libre.

```c
tsl(int *flag)
{
    int x = flag; // Guarda el valor actual del flag en una variable temporal.
    *flag = 1;    // Asigna 1 al flag (ocupa el recurso).
    return x;     // Devuelve el valor previo para comprobar si estaba ocupado.
}


entradaRC()
{
    // Mientras que el flag devuelva 1, se queda esperando (recurso ocupado).
    // Cuando devuelve 0, entra a la regi√≥n cr√≠tica.
    while(tsl(ocupado)){ };
}

salidaRC()
{
    // Libera el recurso para que otros procesos puedan entrar.
    ocupado = 0;
}

```

‚ùå Problemas:

-   Puede causar espera activa e inanici√≥n

### 4. Instrucci√≥n Intercambiar (CAS: Compare And Swap)

CAS es una instrucci√≥n at√≥mica: compara el valor actual de una variable con uno esperado y, si coinciden, la cambia por otro valor.

‚úÖ **Ventajas**

-   Aplica a varios procesos, incluso en multiprocesadores.
-   No requiere estructuras complejas.
-   Permite manejar m√∫ltiples regiones cr√≠ticas.

‚ùå **Desventajas**

-   Usa espera activa: consume CPU mientras espera.
-   Puede causar inanici√≥n si hay muchos procesos esperando.

```c
bool CAS(int* cerrojo, int esperado, int nuevo_valor) {
    if (*cerrojo == esperado) {
        *cerrojo = nuevo_valor;
        return true;  // Intercambio exitoso
    }
    return false;     // No se hizo el cambio
}
```

Este fragmento permite que m√∫ltiples procesos intenten entrar a una regi√≥n cr√≠tica, pero solo uno lo logra cuando la condici√≥n de cerrojo == 0 se cumple.

### 5. Algoritmos Que no se Utilizan

Estas t√©cnicas no son escalables ni seguras en sistemas modernos, por lo que no se dara detalles:

-   No usar multitarea
-   Deshabilitar interrupciones

### 6. Semaforos

#### Definici√≥n

Un sem√°foro es una herramienta de sincronizaci√≥n de procesos. permite el ordenamiento de las operaciones que realizan los procesos en el tiempo.

Internamente, un sem√°foro es una variable entera protegida, que solo puede ser modificada a trav√©s de dos operaciones at√≥micas:

-   `P()`, `down()` o `wait()`: Disminuye el valor del sem√°foro. Si el valor queda negativo, el proceso se bloquea.
-   `V()`, `up()` o `signal()`: incrementa el valor del sem√°foro. Si hay procesos bloqueados, despierta uno.

Adem√°s, existe una operaci√≥n de inicializaci√≥n, donde se define el valor inicial.

> A diferencia de una bandera, las operaciones down y up son at√≥micas, lo que garantiza que dos procesos no puedan modificar el valor al mismo tiempo.

#### Tipo

-   **Binario o Mutex (booleano)**: Solo pueden tomar los valores 0 y 1. Se usa principalmente para mutua exclusi√≥n (una sola entidad accede al recurso).
-   **Contadores**: Pueden tomar valores enteros (positivos, nulo o negativo). Permite controlar el acceso a un conjunto de recursos id√©nticos, como n impresoras.

#### Semaforos con/sin espera activa

-   **Con espera activa (busy waiting)**:
    El proceso ocupa CPU mientras espera que el sem√°foro le permita avanzar Ineficiente.

-   **Sin espera activa (bloqueante)**:
    El proceso se bloquea autom√°ticamente si no puede continuar, liberando la CPU para otros. Este es el modelo ideal y el que se usar en la pr√°ctica y en sistemas operativos reales.

üß† Nos enfocaremos en sem√°foros sin espera activa.

Se incorporan dos operaciones at√≥micas en el sistema:

-   `block():`

Coloca al proceso actual en la cola del sem√°foro. Cambia su estado a inactivo o bloqueado.

-   `wakeup():`

Despierta a uno de los procesos en la cola. Lo pasa del estado de bloqueado a listo. La elecci√≥n de qu√© proceso activar la decide el kernel (no la funci√≥n).

## Comunicaci√≥n Entre Procesos (IPC)

### Formas de Comunicaci√≥n

2 formas de comunicarnos:

-   **Comunicaci√≥n a trav√©s de un √°rea com√∫n de memoria (comunicaci√≥n indirecta)**

Los procesos env√≠an y reciben los mensajes entre s√≠. Requieren un bus para ellos.

-   **Comunicaci√≥n por intercambio de mensajes (comunicaci√≥n directa)**

Los mensajes son enviados a un buzon o mailbox y se retiran del buz√≥n

![](/imgs/clase-5/comunicacion.png)

> A pide un mailbnox y env√≠a MSG, b se activa y recibe MSG

En todo modelo de comunicaci√≥n, se tiene un emisor, receptor, medio de comunicaci√≥n, mensaje y protocolo. Esta informaci√≥n puede verse representado por los **mailbox**. interfaz entre procesos.

### Tipos de Sincronizaciones Mediantes Mensajes

-   **Comunicaci√≥n Sincr√≥nica**

    1. El emisor se bloquea hasta que el receptor est√© listo para recibir el mensaje.
    2. El receptor se bloquea si a√∫n no hay mensaje disponible.
    3. Una vez que el mensaje se entrega, ambos procesos contin√∫an su ejecuci√≥n concurrentemente.

-   **Comunicaci√≥n Asincr√≥nica**

    1. Las primitivas no bloquean a los procesos.
    2. El emisor contin√∫a su ejecuci√≥n inmediatamente, sin esperar al receptor.
    3. El receptor sigue ejecut√°ndose, incluso si no tiene mensajes pendientes.
    4. La gesti√≥n de mensajes pendientes depende de la implementaci√≥n.

-   **Comunicaci√≥n Semi-Sincr√≥nica**
    -   El send es no bloqueante: el emisor env√≠a y sigue su ejecuci√≥n.
    -   El receive es bloqueante: el receptor se detiene hasta recibir el mensaje.
    -   Riesgoso porque puede producirse una acumulaci√≥n de mensajes en la cola del receptor si este no atiende r√°pidamente.

### Modelo Producto-Consumidor (secuencia FIFO)

-   **Productor**: _Produce_ algo y lo _deposita_ en una cola
-   **Consumidor**: _Recupera_ lo que dejo el producto en la cola y lo _consume_
-   **Buffer**: Zona de memoria utilizada para amortiguar las diferencias de velocidad entre dos procesos. Almacena temporalmente los elementos generados por productos.

![](/imgs/clase-5/productor-consumidor.png)

Se utilizan las respecticas funcionnes mostradas en la representaci√≥n.

Se tiene diferentes algoritmos para el modelo presentado

#### Con sleep() & wakeup()

-   `sleep()` -> bloquea al proceso actual.
-   `wakeup()` -> desbloquea un proceso espec√≠fico.

Usa una variable `cont` que indica la cantidad de lugares ocupados que tiene el buffer, donde N es el total de lugares.

```c
// Productor
p() {
    while (1) {
        x = producir(); // Produce un elemento
        if (cont == N)  // Si el buffer est√° lleno
            sleep();    // Se bloquea esperando espacio
        cont++;         // Aumenta el contador de elementos en el buffer
        ingresar(x);    // Deposita el elemento en el buffer
        if (cont == 1)  // Si el buffer estaba vac√≠o antes
            wakeup(c);  // Despierta al consumidor
    }
}

// Consumidor
c() {
    while (1) {
        if (cont == 0)     // Si el buffer est√° vac√≠o
            sleep();       // Se bloquea esperando un nuevo elemento
        x = sacar();       // Extrae un elemento del buffer
        cont--;            // Disminuye el contador
        if (cont == N - 1) // Si hab√≠a espacio lleno antes
            wakeup(p);     // Despierta al productor
        consumir(x);       // Procesa el dato consumido
    }
}

```

‚ùå Problema: Condici√≥n de carrera.

Si el consumidor revisa cont == 0 y es interrumpido antes de dormir, el productor puede producir, hacer wakeup, pero como el consumidor a√∫n no est√° dormido, la se√±al se pierde, y el consumidor queda bloqueado para siempre.

#### Con Contadores de eventos

`e` es una variables especiales con tres operaciones primitivas:

-   **read(e)** -> devuelve el valor de _e_.
-   **advance(e)** -> Incrementa at√≥micamente el valor de _e_ en 1.
-   **await(e, v)** -> espera hasta que e ‚â• v.
    -   Solo incrementa el valor, nunca disminuye
    -   Siempre se inician en cero

```c
// Variables globales
int ing = 0;     // Eventos de ingreso al buffer
int sacados = 0; // Eventos de consumo

// Productor
p() {
    int prod = 0;
    while (1) {
        x = producir();           // Produce un elemento
        prod++;                   // Actualiza su n√∫mero de producci√≥n
        await(N, prod - sacados); // Espera si hay demasiados productos sin consumir
        ingresar(x);              // Deposita el elemento
        advance(ing);             // Incrementa el contador de elementos ingresados
    }
}

// Consumidor
c() {
    int sec = 0;
    while (1) {
        sec++;            // N√∫mero de secuencia de consumo
        await(ing, sec);  // Espera hasta que haya un √≠tem disponible
        x = sacar();      // Extrae del buffer
        advance(sacados); // Marca el √≠tem como consumido
        consumir(x);      // Lo procesa
    }
}

```

Se tienen las siguientes variables extras:

-   **ing**: cantidad acumulada de √≠tems producidos.
-   **sacados**: cantidad acumulada de √≠tems consumidos.

#### Con Sem√°foros¬†

Se utilizan 3 sem√°foros:

-   **mutex = 1** -> Exclusi√≥n mutua
-   **vacio = N** -> Lugares vac√≠os en el buffer
-   **lleno = 0** -> Lugares ocupados en el buffer

```c
// Variables sem√°foro
semaphore mutex = 1; // Exclusi√≥n mutua para acceder al buffer
semaphore vacio = N; // Cantidad de lugares libres en el buffer
semaphore lleno = 0; // Cantidad de elementos disponibles para consumir

// Productor
p() {
    while (1) {
        x = producir(); // Produce un elemento
        P(vacio);       // Espera que haya espacio en el buffer
        P(mutex);       // Entra a la secci√≥n cr√≠tica
        ingresar(x);    // Coloca el √≠tem en el buffer
        V(mutex);       // Sale de la secci√≥n cr√≠tica
        V(lleno);       // Se√±ala que hay un nuevo √≠tem para consumir
    }
}

// Consumidor
c() {
    while (1) {
        P(lleno);    // Espera hasta que haya un elemento en el buffer
        P(mutex);    // Entra a la secci√≥n cr√≠tica
        x = sacar(); // Toma un √≠tem del buffer
        V(mutex);    // Sale de la secci√≥n cr√≠tica
        V(vacio);    // Se√±ala que hay un espacio libre en el buffer
        consumir(x); // Procesa el √≠tem
    }
}
```

## Bloqueos Mutuos (DeadLocks)

### Definici√≥n

-   **Deadlock**: Situaci√≥n cuando dos o m√°s procesos poseen determinados recursos, y cada uno queda detenido, a la espera de alguno de los que tiene el otro. El sistema puede seguir operando normalmente, pero ninguno de los procesos involucrados podr√°n avanzar. Quedando permamentemente bloqueados. Se da por lo motivos:

    -   Comunicaci√≥n entre procesos
    -   Petici√≥n de Recursos

-   **Inanici√≥n**: Situaci√≥n en que un proceso no puede¬†avanzar en su ejecuci√≥n dado que necesita recursos que est√°n (alternativamente) asignados a otros procesos.

### Grafo de Asignaci√≥n de Recursos (Resource Allocation Graph )

Estos grafos est√°n formados por dos elementos:

-   P = Un conjunto de v√©rtices formado por los procesos y los recursos del sistema
-   R = Un conjunto de arcos que representan la asignaci√≥n o solicitud de recursos.

Se tiene el siguiente ejemplo:

![](/imgs/clase-5/deadlocks.png)

Los recursos fueron representados con cuadrados y los procesos con c√≠rculos. Un arco de Pi a Rj significa que el proceso Pi solicito el recurso Rj. Un arco de Rj a Pi significa que el recurso Rj esta asignado al proceso Pi .

1. Un arco dirigido de P1 a R1 indica que P1 pidi√≥ el recurso R1 y est√° esperando. (Fig 4.13a)
2. Un arco dirigido de R1 a P1 indica que P1 pidi√≥ el recurso R1 y R1 est√° asignado a P1. (Fig 4.13b)
3. Un conjunto de arcos como se indica en la Fig 4.13c indica que est√° en deadlock

El resultado de este producto, es una espera circular de forma constante; Hay una cadena circular de procesos en la que cada uno mantiene a uno¬†o m√°s recursos que son requeridos por el siguiente proceso de la cadena

### Condiciones Necesarias de Coffman

Se necesitan 4 condiciones simultaneas para que se produzca un deadlock:

-   **Falta de Mutua Exclusi√≥n**: Los procesos reclaman control exclusivo de los recursos que piden.
-   **Retener y Esperar**: Un proceso retiene un recurso y no lo libera hasta que lo ejecute o pida adquirir nuevos recursos
-   **No Expropiaci√≥n**: Si el sistema operativo no puede liberar el recurso
-   **Espera Circula (grafo anterior)**: Hay una cadena circular de procesos en la que cada uno mantiene a uno¬†o m√°s recursos que son requeridos por el siguiente proceso de la cadena

### Estrategias para Tratar los Bloqueos

#### Ignorarlos y Pensar que nunca ocurrio

La mayoria de los sistemas incluyen este. Forma m√°s simple.

#### Prevenirlo o Evitarlo

Se debe evitar que se de alguna de las condiciones de Coffman:

-   **Falta de Mutua Exclusi√≥n**: Se generan mas problemas
-   **Retener y Esperar**: Se puede utilizar el metodo de COBOL; cuando empieza a ejecutar un proceso, pide todos los recursos juntos. Hasta que no termina no libera. Pedo tambien tiene un costo
-   **No Expropiaci√≥n**: 2 metodos:
    -   Si un proceso solitica un recurso que no est√° disponible, √©ste debe devolver todos aquellos recursos asignados
    -   Si un proceso pide un recurso que tiene otro proceso, el sistema obliga a liberar los recursos del otro proceso. Puede generar inaniaci√≥n por no poder finalizar su circular
-   **Espera Circula (grafo anterior)**: Romper alguna de las 3 condiciones previas.

#### Detectar y Recuperar

Abortar un proceso cuando detecta un deadlock.

‚úÖ **Ventajas**

-   No limita el acceso a los recursos

‚ùå **Desventajas:**

-   Decidir la frecuencia con que se llevar√° a cabo el algoritmo de detecci√≥n.

Hay varios metodos para esto:

-   Abortar todos los procesos involucrados
-   Abortar los procesos uno a uno, hasta que el deadlock desaparezca.
-   Quitar un recurso a un proceso y entreg√°rselo a otro que lo haya solicitado.
-   Llevar el proceso a un punto anterior al de haberle sido asignado el recurso causante del Deadlock. Hacer un backup de cada proceso en un punto anterior: _ChekPoint_. A este proceso de reinicio se lo llama _Rollback_.

# Practica Semaforos para los Procesos

# üß† M√≥dulo 5: Administraci√≥n de Memoria

## Funciones y Operaciones

### üîç Consideraciones Generales

Por dise√±o, el\*√∫nico espacio de memoria que el procesador puede utilizar directamente es la memoria central (MC), tambi√©n llamada memoria principal (MP) o RAM. No se utilizan otras memorias para ejecutar instrucciones debido a:

-   **üìå Cach√©** -> Se usa para mejorar el rendimiento. Solo replica el contenido de la MC para acelerar el acceso. No es direccionable directamente por el procesador.

-   **üìå Registros** -> Son muy pocos\*\* y muy peque√±os. Se usan para operaciones internas del CPU, no para almacenar programas o datos permanentes.

-   **üìå Disco (almacenamiento)** -> Aparte de que son muy lentos, no se puede por ser un dispositivo de entrada y salida, no esta conectado directamente a los busses del sistema. Solo sirve para almacenamiento secundario.

Por estas razones, los programas deben cargarse en la memoria central antes de ejecutarse.

### üó∫Ô∏è Espacio de Direccionamiento

En los sistemas modernos, los datos se mueven por el bus de datos, y las instrucciones que los manejan son direccionadas por el Program Counter (PC), un registro que apunta a la pr√≥xima direcci√≥n de memoria a ejecutar. La cantidad de memoria que puede usar el sistema depende de la cantidad de bits del direccionamiento que tenga el CPU, por ejemplo:

| Arquitectura | Bits de Direcci√≥n | Capacidad de Direccionamiento  |
| ------------ | ----------------- | ------------------------------ |
| 16 bits      | `2^16`            | 65,536 bytes = **64 KB**       |
| 32 bits      | `2^32`            | 4,294,967,296 bytes = **4 GB** |
| 64 bits      | `2^64`            | ‚âà 1.8 √ó 10¬π‚Åπ bytes = **16 EB** |

Para sistemas de 32 bits que requieren m√°s de 4 GB de RAM, se puede usar **PAE** (_Physical Address Extension_), una tecnolog√≠a que a√±ade m√°s bits al direccionamiento f√≠sico, permitiendo acceder a m√°s memoria aunque el espacio l√≥gico siga siendo de 32 bits.

### ‚öôÔ∏è Hardware: MMU (Memory Management Unit)

La **MMU (Unidad de Gesti√≥n de Memoria)** es un componente de hardware que se encarga de gestionar el acceso a la memoria central en sistemas con CPU multitarea\*

Cuando m√∫ltiples programas se ejecutan al mismo tiempo, el sistema operativo necesita decidir c√≥mo y d√≥nde ubicarlos en la memoria f√≠sica. La MMU se encarga de hacer cumplir esas decisiones y proteger los espacios de cada proceso.

Algunas de sus principales funcionalides:

-   **Traducci√≥n de direcciones l√≥gicas a f√≠sicas** -> Convierte las direcciones que utiliza un programa en sus instrucciones (direcciones l√≥gicas o virtuales) a direcciones reales de memoria (f√≠sicas).

-   **Protecci√≥n de memoria** -> Cada proceso tiene un espacio reservado en memoria. La MMU usa **registros base y l√≠mite** para impedir que un proceso acceda a la memoria de otro.

-   **Soporte para memoria virtual** _(tema que se ver√° m√°s adelante)_ -> Permite que un proceso use m√°s memoria de la que f√≠sicamente hay disponible, gracias al uso combinado de RAM y disco.

![](/imgs/clase-6/gestionar%20programas.png)

üîí La MMU act√∫a como un "guardia de seguridad" que impide que un proceso interfiera con otro en memoria. Usa **tablas y registros** para mantener este control autom√°ticamente en cada acceso de memoria.

### ‚öôÔ∏è Hardware: Cach√©

La velocidad del procesador es significativamente mayor que la de la memoria central (MC). Esta diferencia genera un cuello de botella, ya que el CPU debe esperar a que los datos lleguen desde la RAM, afectando su rendimiento.

Para mitigar este problema, los sistemas incorporan una memoria intermedia llamada cach√©. La cach√© es una memoria r√°pida y de menor tama√±o, ubicada entre la memoria principal (RAM) y los registros del CPU. Su funci√≥n es almacenar copias de los datos m√°s utilizados o recientemente accedidos desde la memoria principal, anticip√°ndose a futuras solicitudes del procesador.

-   Reduce la cantidad de accesos a la memoria RAM.
-   Aumenta la velocidad de ejecuci√≥n del CPU.
-   Minimiza los tiempos de espera (latencia).

El precio de un sistema puede variar considerablemente seg√∫n el tama√±o y nivel de la cach√©:

-   **Nivel 1 (L1)**: Cach√© peque√±a, ultrarr√°pida y muy costosa (ubicada dentro del CPU).
-   **Nivel 2 (L2)**: M√°s grande que L1, un poco m√°s lenta, pero tambi√©n m√°s econ√≥mica.
-   Algunos sistemas incluyen una **cach√© de nivel 3 (L3)**, compartida entre n√∫cleos de CPU.

üìå Cuanto m√°s grande y r√°pida es la cach√©, **mayor ser√° el rendimiento**, pero tambi√©n el **costo del procesador**.

### Como se maneja el Espacio de Memoria de un Proceso

Cuando se crea un proceso, el sistema operativo le asigna un espacio de memoria estructurado en varias secciones bien definidas. Cada secci√≥n tiene un prop√≥sito espec√≠fico durante la ejecuci√≥n del programa:

-   **Secci√≥n de Texto (Text Segment)** -> Codigo del programa, las instrucciones en ASM. Solo lectura.
-   **Datos** -> Alberga las variables est√°ticas y globales declaradas en el programa. Se llaman "est√°ticas" porque ocupan siempre la misma posici√≥n de memoria durante toda la ejecuci√≥n del proceso.
-   **Espacio Libre(HEAP)** -> Regi√≥n de memoria utilizada para la asignaci√≥n din√°mica; crear estructuras de datos durante la ejecuci√≥n del programa. En C, se utiliza `malloc()`, `calloc()`, `realloc()`, y `free()` para gestionarlo.
-   **Pila de Llamadas(Stack)** -> La pila crece hacia abajo (desde la parte superior del espacio de memoria hacia direcciones menores). Espacio utilizado para almacenar:
    -   Llamadas a funciones
    -   Variables locales
    -   Direcciones de retorno

![](/imgs/clase-2/memoria-cpu.png)

### Como se manejan las Direcciones

El manejo de direcciones de memoria\*depende del hardware y del sistema operativo.

El compilador reemplaza variables y funciones por direcciones de memoria, pero estas deben ser traducidas a direcciones relativas o din√°micas para poder coexistir con otros procesos sin conflictos. Existen tres enfoques principales, seg√∫n **cu√°ndo** se realiza la conversi√≥n de las direcciones l√≥gicas del programa a direcciones f√≠sicas reales en memoria:

| Estrategia            | Traducci√≥n ocurre en...    | Flexible   | Riesgo de conflicto |
| --------------------- | -------------------------- | ---------- | ------------------- |
| Tiempo de compilaci√≥n | Al compilar                | ‚ùå No      | ‚úÖ Alto             |
| Tiempo de carga       | Al iniciar el programa     | ‚ö†Ô∏è Parcial | ‚ö†Ô∏è Medio            |
| Tiempo de ejecuci√≥n   | Mientras el programa corre | ‚úÖ S√≠      | ‚ùå Bajo             |

#### üß± 1. En Tiempo de Compilaci√≥n

-   Las **direcciones son fijas (absolutas)**.
-   El programa se compila indicando que se ejecutar√° en una **posici√≥n espec√≠fica de memoria**.
-   ‚ùå Problema: si dos programas se cargan en la misma direcci√≥n, **se pisan y provocan errores**.

> Ejemplo: antiguamente usado en sistemas monoprogramados.

#### üì¶ 2. En Tiempo de Carga

-   El **loader del sistema operativo** calcula las direcciones al **momento de cargar el programa en memoria**.
-   El compilador genera direcciones **relativas** y el loader las **ajusta seg√∫n la direcci√≥n base** asignada al proceso.

#### üîÅ 3. En Tiempo de Ejecuci√≥n

-   Las direcciones se **resuelven din√°micamente** mientras el programa se est√° ejecutando.
-   El programa **no hace referencia a posiciones fijas**, sino que utiliza:

    -   Una **posici√≥n base**
    -   Un **desplazamiento (offset)**

-   La traducci√≥n la realiza el hardware mediante la **MMU (Unidad de Gesti√≥n de Memoria)**.

> ‚úÖ Es el m√©todo m√°s flexible y seguro, ya que permite:
>
> -   Compartir memoria
> -   Implementar memoria virtual
> -   Proteger procesos entre s√≠

## Asignaci√≥n de Memoria Contigua

Definimos como utilizar la memoria principal para utilizar los programas. Para esto, se tienen 3 algoritmos.

### Sistema Monoprogramado (Unica Partici√≥n)

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Sistema%20Monoprogramado.png)

En los sistemas monoprogramados o por lotes, el sistema operativo casi no necesitaba gestionar la memoria, porque solo hab√≠a un proceso en ejecuci√≥n a la vez. Una vez cargado el sistema operativo en memoria, todo el resto del espacio libre quedaba disponible para ese √∫nico programa. No exist√≠a la necesidad de compartir la memoria ni de proteger un proceso de otro. Sigue la siguiente secuencia:

1. El sistema operativo (SO) se carga primero en una parte fija de la memoria (parte baja).
2. El procesador tiene un **registro de l√≠mite** (_boundary register_) que delimita la zona segura de memoria.
3. Todo el espacio restante queda disponible para un √∫nico programa de usuario.
4. El procesador impide que el programa de usuario acceda a zonas protegidas del SO, usando ese l√≠mite.

El **registro l√≠mite** indica la direcci√≥n m√≠nima v√°lida que un proceso puede utilizar. Si un proceso intenta acceder por debajo de ese l√≠mite, se produce una violaci√≥n de acceso (protecci√≥n de memoria). Esto asegura que el proceso **no pueda sobrescribir el c√≥digo del SO**.

### Particiones Fijas

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20particiones%20fijas.png)

En este esquema, la memoria principal se divide en particiones de tama√±o fijo, previamente definidas por el sistema operativo. Una vez cargado el Sistema Operativo (SO), el resto de la memoria se divide en bloques (particiones). Cada proceso ser√° cargado en la partici√≥n m√°s adecuada seg√∫n su tama√±o\*\*, y la cola de trabajos se recorrer√° en busca de un espacio disponible. La cantidad de particiones define cu√°ntos procesos concurrentes se pueden ejecutar. No importa si hay memoria libre entre procesos, no se reutiliza din√°micamente. Se sigue la siguiente secuencia:

1. El SO se carga primero en una regi√≥n protegida de memoria.
2. El resto se divide en particiones: Partici√≥n 1, Partici√≥n 2, Partici√≥n 3, etc...
3. Los procesos esperan en una cola de trabajos hasta que una partici√≥n se libere.
4. Un proceso es colocado en una partici√≥n del tama√±o adecuado (si la hay).

Si un programa necesita `X` bytes y tengo una partici√≥n de `Y` bytes...

| Comparaci√≥n | Resultado                                                             |
| ----------- | --------------------------------------------------------------------- |
| `X > Y`     | ‚ùå No puede ejecutarse. No entra en la partici√≥n.                     |
| `X = Y`     | ‚úÖ Se ejecuta normalmente, sin desperdicio.                           |
| `X < Y`     | ‚ö†Ô∏è Se ejecuta, pero queda espacio sin usar ‚Üí _Fragmentaci√≥n interna_. |

Este modelo **puede combinarse con memoria virtual**. Cuando no hay suficiente memoria f√≠sica disponible, se puede usar **espacio en disco (swap)** para simular memoria adicional.

### Particiones Variables

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20particiones%20Variables.png)

En este modelo, la memoria se asigna din√°micamente en funci√≥n del tama√±o del proceso a ubicar. Es decir, no hay bloques fijos como en las particiones est√°ticas: el sistema crea particiones del tama√±o exacto necesario en el momento. Sigue la siguiente secuencia:

1. El sistema operativo se carga primero en la memoria.
2. Los procesos se ubican en las regiones de memoria libres y adecuadas seg√∫n su tama√±o.
3. Al finalizar un proceso, su bloque queda disponible y puede ser reutilizado por otros.
4. Con el tiempo, puede generarse fragmentaci√≥n externa.

¬øD√≥nde ubicar un nuevo proceso si hay varios huecos (holes) de distintos tama√±os? Para eso se siguen diferentes algoritmos:

| Algoritmo     | Descripci√≥n                                                                  | Peso Computacional |
| ------------- | ---------------------------------------------------------------------------- | ------------------ |
| **First Fit** | Asigna el proceso al **primer hueco** suficientemente grande que encuentra.  | ‚ö° R√°pido (ligero) |
| **Best Fit**  | Busca el **bloque m√°s justo posible**, donde sobre menos memoria.            | üê¢ Lento (pesado)  |
| **Worst Fit** | Busca el **hueco m√°s grande**, para evitar fragmentaci√≥n en espacios chicos. | üê¢ Lento (pesado)  |

Puede usarse memoria virtual.

![](/imgs/clase-6/Asignacion-Memoria/Compactacion.png)

A medida que los procesos se crean y terminan, la memoria libre queda dividida en huecos dispersos (**fragmentaci√≥n externa**).  
Esto dificulta la asignaci√≥n de nuevos procesos aunque haya suficiente memoria total disponible.

Para solucionar esto, se utiliza la **compactaci√≥n**. Es una operaci√≥n costosa que reubica todos los procesos en memoria contigua para consolidar el espacio libre en un solo bloque.

### üìä Tabla Comparativa de Esquemas de Asignaci√≥n de Memoria Contigua

| Caracter√≠stica                 | üü¶ Monoprogramado (√önica partici√≥n) | üü© Particiones Fijas                          | üü® Particiones Variables                  |
| ------------------------------ | ----------------------------------- | --------------------------------------------- | ----------------------------------------- |
| üî¢ N¬∫ de procesos concurrentes | 1 solo                              | Igual al n√∫mero de particiones                | Ilimitado (seg√∫n memoria disponible)      |
| ‚öíÔ∏è Asignaci√≥n de memoria       | Est√°tica y √∫nica                    | Est√°tica, dividida en bloques predeterminados | Din√°mica (ajustada al tama√±o del proceso) |
| üí• Fragmentaci√≥n               | No                                  | Interna                                       | Externa                                   |
| üßπ Soluci√≥n a la fragmentaci√≥n | No necesaria                        | No se suele resolver                          | Compactaci√≥n (costosa)                    |
| üîÅ Reutilizaci√≥n de memoria    | No aplica                           | Solo si se libera toda la partici√≥n           | S√≠, con gesti√≥n din√°mica                  |
| ‚öôÔ∏è Algoritmos de asignaci√≥n    | No aplica                           | No aplica                                     | First Fit, Best Fit, Worst Fit            |
| üì¶ Flexibilidad                | Nula                                | Baja                                          | Alta                                      |
| üíæ Soporte de Memoria Virtual  | ‚ùå No                               | ‚úÖ Posible                                    | ‚úÖ Posible                                |
| ‚è≥ Coste de administraci√≥n     | Muy bajo                            | Bajo                                          | Medio - Alto                              |

### Segmentaci√≥n

#### Definici√≥n

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Segmentacion.png)

La segmentaci√≥n es una t√©cnica de administraci√≥n de memoria que divide la memoria l√≥gica de un programa en segmentos de tama√±o variable.  
Cada segmento representa una unidad l√≥gica o funcional del programa, como:

-   C√≥digo (read only, execution)
-   Tabla de S√≠mbolos
-   Stack
-   Heap
-   Bibliotecas compartidas (shared libraries)

Estos segmentos pueden tener **diferentes tipos de acceso**: solo lectura, escritura o ejecuci√≥n. Adem√°s, pueden **compartirse entre procesos**, como ocurre con las bibliotecas din√°micas.

#### üìå Caracter√≠sticas

-   ‚úÖ **Tama√±o variable**: A diferencia de la paginaci√≥n, que usa bloques fijos, los segmentos pueden ser de cualquier tama√±o.
-   üß† **Separaci√≥n l√≥gica**: Cada segmento representa una parte espec√≠fica del programa.
-   ‚ôªÔ∏è **Compartici√≥n**: Algunos segmentos pueden ser reutilizados entre procesos.
-   üíæ **Memoria virtual compatible**: Permite integraci√≥n con t√©cnicas modernas de administraci√≥n.
-   üîÅ **Gesti√≥n similar a particiones variables**: El espacio libre se fragmenta de forma externa y puede ser compactado.
-   ‚ö†Ô∏è **Fragmentaci√≥n externa**: Aunque puede compactarse, esto implica overhead (costo de CPU).
-   üß∞ **Requiere soporte de hardware**: Se necesita una **MMU** (Unidad de Gesti√≥n de Memoria) con soporte de segmentaci√≥n.

#### üõ† ¬øC√≥mo se administra?

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Segmentacion%20Administracion.png)

1.  La **CPU** solicita una direcci√≥n l√≥gica compuesta por:  
    `s:d` ‚Üí donde `s = n√∫mero de segmento` y `d = desplazamiento (offset)`.
2.  El sistema operativo mantiene una **SMT (Segment Memory Table)** por cada proceso. La **SMT** guarda:
    - N√∫mero de segmento
    - Tama√±o del segmento.
    - Direcci√≥n base en memoria f√≠sica
3.  Cunado se requiere una direcci√≥n. El **MMU** traduce la direcci√≥n l√≥gica a f√≠sica. Verifica que `d < tama√±o del segmento`:
    -   Si es v√°lido: **direcci√≥n f√≠sica = base del segmento + desplazamiento**
    -   Si no es v√°lido: **segmentation fault**.

#### ‚úÖ Ejemplo pr√°ctico

Supongamos que un programa tiene los siguientes segmentos:

| Segmento | N¬∫ Segmento (`s`) | Tama√±o | Direcci√≥n Base |
| -------- | ----------------- | ------ | -------------- |
| C√≥digo   | 0                 | 2000B  | 1000           |
| Datos    | 1                 | 1000B  | 4000           |
| Stack    | 2                 | 500B   | 7000           |

Si el programa quiere acceder a la direcci√≥n `1:100`, entonces:

1.   SMT busca el segmento `1` ‚Üí Base = `4000`
2.   Verifica que `100 < 1000` ‚Üí ‚úîÔ∏è
3.   Direcci√≥n f√≠sica = `4000 + 100 = 4100`

### Paginaci√≥n

#### Definici√≥n

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Paginacion.png)

La paginaci√≥n es una t√©cnica de administraci√≥n de memoria que divide tanto la memoria l√≥gica (programa) como la memoria f√≠sica (RAM) en bloques del mismo tama√±o. Para comprender mejor los conceptos:
- üîπ **P√°gina (page)**: Unidad de divisi√≥n de la **memoria l√≥gica** del proceso (programa).
- üîπ **Marco (frame)**: Unidad de divisi√≥n de la **memoria f√≠sica** del sistema.
- üìê **Tama√±o**: Las p√°ginas y marcos tienen igual tama√±o (potencias de 2, ej. 4KB, 8KB...).

### ‚öôÔ∏è ¬øC√≥mo funciona?

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Paginacion%20Bus.png)

El bus de direcciones se parte en 2:
- `p` ‚Üí N√∫mero de p√°gina. Bits para cantidad de paginas (numero de pagina)
- `d` ‚Üí Desplazamiento (offset) dentro de esa p√°gina. Bits de desplazamiento.

> **Direcci√≥n f√≠sica = direcci√≥n base del marco + desplazamiento**

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Paginacion%20Administracion.png)

1. Se divide el espacio l√≥gico del programa en p√°ginas
2. Se divide la ram en frames de igual tama√±o a las paginas
3. Se asigna a cada p√°gina un frame disponible. 
4. Se guarda en una `MPT` (Memory Page Table) por proceso el:
    - Nro de pagina
    - Tama√±o
    - Direcci√≥n de Inicio
5. Cuando se requiere una direcci√≥n, se llama al MMU, traduce direcciones l√≥gicas a f√≠sicas. Se recupera el inicio del frame en la MPT a partir de la pagina. 
   - `Direcci√≥n L√≥gica = P√°gina (p) + Desplazamiento (d)`
   - `Direcci√≥n F√≠sica = Direcci√≥n Base del Marco + d`

Para indicar si un frame esta ocupado o libre, se utiliza el `MFT` (Memory Frame Table) con un valor booleano.

#### Caracteristicas

<!-- Fragmentaci√≥n -> Se fragmenta por pagina y se reduce la externa. Esta dado por los tama√±os a los frames y paginas, dado por la formula: [tama√±o] - 1byte(Unidad minima para poner en la pagina) por frame -->


| Caracter√≠stica             | Detalle                                                                 |
|---------------------------|-------------------------------------------------------------------------|
| Fragmentaci√≥n             | ‚úÖ Solo interna. Mucho menor que en segmentaci√≥n. Se fragmenta por pagina|
| Reasignaci√≥n              | ‚úÖ Los marcos pueden reutilizarse f√°cilmente.                           |
| Hardware requerido        | ‚ùó Alto. Se necesita soporte para MMU, MPT, MFT y TLB.                   |
| Velocidad                 | üöÄ Muy eficiente con TLB y cach√©, pero costoso sin ellas.               |
| Compartici√≥n              | ‚úÖ Es posible entre procesos (p√°ginas solo lectura).                    |

- Tama√±o Pagina optima, depende del tama√±o de MC:
  - Paginas chicas = aumenta mucho el tama√±o de la tabla de paginas, PCB muy grande y transferencias costosas.
  - Paginas grandes = Mucha fragmentaci√≥n interna. Se desperdicia espacio. Ejemplo: si se tiene una pagina de 1MB y el programa ocupa 1KB, se desperdicia cas√≠ un MB

#### ‚ö°Ô∏è Optimizaci√≥n: TLB (Translation Lookaside Buffer)

El soporte de hardware es muy costoso, por lo que se utilizan dispositivos extras como el cache y `TLB` (Translation Lookaside Buffer, Buffer de traduci√≥n anticipada). Su relaci√≥n es muy similar a la de cache con el CPU.

- **Direccionamiento con TLB**

![](/imgs/clase-6/Asignacion-Memoria/Estructura%20Paginacion%20TLB.png)

TLB es una memoria donde se carga la tabla de paginas, o una parte. Es muy rapida y tiene el mismo tiempo de busqueda para todas las paginas. Sigue el siguiente flujo:

1. Se genera una direcci√≥n l√≥gica (n√∫mero de p√°gina `p`, desplazamiento `d`).
2. La MMU consulta el TLB con `p`:
   - Si est√°, obtiene el marco `f` correspondiente.
   - Si no est√°, consulta la MPT para obtener `f`, y puede almacenar esa entrada en el TLB.
3. Calcula la direcci√≥n f√≠sica: `f + d`.

- **Direccionamiento con TLB y Cache**

La diferencia es que se le suma una cache como otra memoria intermedia. Primero, se busca en TLB, si no se encuentra se va a cache, y si no se encuentra se va a MC

#### Paginaci√≥n Multinivel


La paginaci√≥n multinivel es una extensi√≥n del esquema de paginaci√≥n tradicional. Se utiliza para **evitar el uso de una √∫nica tabla de p√°ginas demasiado grande** en sistemas con direcciones l√≥gicas amplias (como en arquitecturas de 32 o 64 bits). En sistemas con direcciones grandes (por ejemplo, 32 bits), mantener una **tabla de p√°ginas plana** (un nivel) requiere un espacio inmenso:
> Si una p√°gina es de 4 KB (2¬π¬≤ bytes), entonces hay `2¬≤‚Å∞` p√°ginas ‚Üí tabla con m√°s de **un mill√≥n de entradas**.

![](/imgs/clase-6/Asignacion-Memoria/Paginacion%20Multinivel.png)

En la paginaci√≥n multinivel se **divide la direcci√≥n l√≥gica** en varias partes, que acceden a **m√∫ltiples niveles de tablas**:
- `p‚ÇÅ`: √çndice para la **tabla de p√°ginas externas**.
- `p‚ÇÇ`: √çndice para la **tabla de p√°ginas internas** (que apunta a los marcos).
- `d`: Desplazamiento dentro de la p√°gina.

Se siguen los siguientes pasos:

1. Se recibe la **direcci√≥n l√≥gica** dividida como `p‚ÇÅ | p‚ÇÇ | d`.
2. Con `p‚ÇÅ` se accede a la **tabla de p√°ginas externas**.
3. Esta tabla apunta a una **tabla de p√°ginas internas**.
4. Con `p‚ÇÇ` se accede a la p√°gina interna que contiene el n√∫mero de **marco f√≠sico**.
5. Finalmente, se suma el **offset `d`** al marco para obtener la **direcci√≥n f√≠sica en RAM**.

Ejemplo:

![](/imgs/clase-6/Asignacion-Memoria/Paginacion%20Multinivel%20Ejemplo.png)

#### Memoria Compartida

- **Memoria Compartida Entre Procesos**

![](/imgs/clase-6/Asignacion-Memoria/Paginacion%20Memoria%20Compartida.png)

En sistemas operativos, la **memoria compartida** permite que varios procesos accedan a las **mismas p√°ginas f√≠sicas de memoria**, lo cual mejora la eficiencia al evitar duplicar informaci√≥n redundante. Pero, se deben seguir unas reglas:
- ‚úÖ Solo se pueden compartir p√°ginas de solo lectura o ejecuci√≥n, como el c√≥digo del programa.
- ‚ùå Las p√°ginas que contienen datos modificables (como variables) no se comparten, ya que podr√≠an generar inconsistencias entre procesos.

- **`Copy on Write` (Copiar al Escribir)** 

T√©cnica optimizada usada cuando se crea un proceso hijo con `fork()`. Se siguen los siguientes pasos



1. Al principio, el proceso padre y el hijo comparten todas las p√°ginas (incluso las de datos), mientras no se modifiquen. 
   - Ambas tablas de p√°ginas apuntan a los mismos marcos de memoria.
   - Estas p√°ginas se marcan como solo lectura temporalmente.

![](/imgs/clase-6/Asignacion-Memoria/Paginacion%20Padre%20Hijo%20Parte%201.png)

2. Si uno de los procesos intenta escribir, ocurre lo siguiente:
   - Se genera una interrupci√≥n por intentar escribir en una p√°gina de solo lectura.
   - El sistema operativo crea una copia privada unicamente de la p√°gina modificada para ese proceso.
   - A partir de ese momento, cada proceso tiene su **propia versi√≥n modificada** de una misma pagina.

![](/imgs/clase-6/Asignacion-Memoria/Paginacion%20Padre%20Hijo%20Parte%202.png)

## Memoria Virtual

### Definici√≥n

![](/imgs/clase-6/Memoria%20Virtual/Memoria%20Virtual.png)

La idea consiste en utilizar almacenamiento secundario como si fuera la principal en caso de dar la capacidad maxima del sistema. La memoria virtual es gestionada y generada por el sistema operativo, transparente por el usuario.

El contenido de los frames se van cargando poco a poco en el almacenamiento secundario.

### Swapping

![](/imgs/clase-6/Memoria%20Virtual/Swapping.png)

El `swapping` es el intercambio entre memorias de distintos niveles. Se tienen 2 operaciones:
- **Swap-in** -> Se produce cuando se realiza un envio desde un dispositivo de menor jerarquia a uno mayor. Como del disco duro a MC
- **Swap-out** -> Lo opuesto

Pol√≠ticas de Administraci√≥n de Memoria Virtual
1. `Fetch (b√∫squeda)` -> Buscar una pagina para llevarla a MC
2. `Placement (colocaci√≥n)` -> A donde debe ubicarse en la MC cuando ya la tenemos
3. `Replacement (reemplazo)` -> Cual es la p√°gina que se va a reemplazar

Algunas consideraciones:
- ¬øQu√© pasa si el proceso a suspender tiene una operaci√≥n de I/O pendiente?
  - Solo se pueden suspender procesos que no tengan operaciones de entrada/salida pendientes, ya que no pueden gestionarse correctamente fuera de RAM.
  - En caso de tener I/O pendiente, el sistema puede usar buffers intermedios del S.O. para almacenar temporalmente los datos. Cuando el proceso vuelve a estar activo, los datos se restauran o contin√∫an desde su estado anterior.
- Swapping excesivo ‚Üí Hiperpaginaci√≥n (thrashing)
  - Cuando el sistema pasa m√°s tiempo intercambiando p√°ginas que ejecutando procesos √∫tiles, se genera un efecto llamado hiperpaginaci√≥n.
  - Esto provoca una ca√≠da fuerte del rendimiento, ralentizando toda la computadora.
  - No solo es un problema de velocidad del disco vs RAM, sino tambi√©n por el overhead de administraci√≥n del swapping.
- ¬øA d√≥nde van las p√°ginas descargadas?
  - Las p√°ginas que se descargan de la memoria central van al espacio de intercambio (swap) en el disco.
- Direcciones virtuales y l√≠mite de memoria virtual
  - El tama√±o m√°ximo de la memoria virtual est√° determinado por la capacidad del espacio de direccionamiento del procesador.
  - Por ejemplo, si se tiene un CPU de 32 bits, entonces el m√°ximo de direcciones que puede manejar es 2¬≥¬≤ = 4GB.
  - Esto implica que la memoria virtual no puede exceder los 4GB, salvo que se usen extensiones como PAE o se tenga una arquitectura de 64 bits.

### Paginaci√≥n bajo demanda

La memoria secundaria guarda y trae paginas enteras. Al iniciar un proceso, existen 2 tecnicas para traer las paginas:
- `Lazy` (flojo/perezoso) -> Solo se cargan las paginas necesarias a medida que se va requiriendo.
- `Eager` (ansioso/gloton) -> Se carga todo al momento de iniciar

### Protocolo al Tener Fallo de p√°gina

1. Verificar en el PCB si la solicitud corresde a una pagina que ya ha sido asignada a este proceso.
2. En caso de que la referencia sea inv√°lida, se finaliza el proceso.
3. Trae la pagina del disco a la memoria. Busca un marco para esa pagina.
4. Una vez cargado en memoria, solicia al disco la lectura de la p√°gina.
5. Una vez finaliado la lectura, modiicamos tanto al PCB como al TLB para indicar la pagina en memoria.
6. Termina la suspensi√≥n del proceso, continuando el esquema normal. El proceso continua sin notar el swapping de la p√°gina.

### Calcular Rendimiento

![](/imgs/clase-6/Memoria%20Virtual/formula%20rendimiento.png)

> - `t‚Çë` -> Tiempo efectivo de acceso a memoria
> - `p` -> Probabilidad de fallo de p√°gina 
> - `ta` -> Tiempo de acceso a memoria (entre 10 y 200 ns)
> - `tf` -> Tiempo que toma atender a un fallo de p√°gina (aprox 8ms)

Ejemplo:

Si p = 1/1000 (Un fallo cada 1000 accesos) 

![](/imgs/clase-6/Memoria%20Virtual/rendimiento%20ejemplo.png)

### Reemplazo de p√°ginas

Debemos elegir que pagina reemplazar para poner la nueva pagina. Para esto, tenemos varios algoritmos para elegir cual.

Una `cadena de referencia` es una secuencia de accesos a p√°ginas de memoria que realiza un proceso durante su ejecuci√≥n. Cada n√∫mero en la cadena representa el n√∫mero de p√°gina que el proceso necesita acceder en ese momento. Se utiliza principalmente para simular y analizar el comportamiento de los algoritmos de reemplazo de p√°ginas. Con ella se puede contar cu√°ntos fallos de p√°gina ocurren y cu√°n eficiente es un algoritmo en un escenario dado.

> **Anomal√≠a de Belady**
> 
> Si tengo una cantidad de frames para un proceso, al darle mas frames deberia tener menos fallo de pagina. Sin embargo, esto es erronea por la anomaliaal utilizar determinado algoritmo. De echo, da m√°s fallos de pagina.

#### Primero en entrar, primero en salir - FIFO

- L√≥gica: Se reemplaza la p√°gina que fue cargada primero, sin importar si se ha utilizado recientemente.
- Implementaci√≥n: Se usa una cola circular; la primera en entrar es la primera en salir.

|‚úÖ **Ventajas**|‚ùå **Desventajas**|
|---------------|-------------------|
|- Facil implementaci√≥n|- Vulnerable a la anomal√≠a de Belady|

Ejemplo:

- Cantidad de frames disponibles: 3
- Cadena de referencia: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1

![](/imgs/clase-6/Memoria%20Virtual/Algoritmo%20FIFO.png)

| Paso | P√°gina | Estado de los marcos | Acci√≥n                |
| ---- | ------ | -------------------- | --------------------- |
| 1    | 7      | 7 \_ \_              | ‚ùå Fallo (inserta 7)   |
| 2    | 0      | 7 0 \_               | ‚ùå Fallo (inserta 0)   |
| 3    | 1      | 7 0 1                | ‚ùå Fallo (inserta 1)   |
| 4    | 2      | 2 0 1                | ‚ùå Fallo (reemplaza 7) |
| 5    | 0      | 2 0 1                | ‚úÖ Hit                 |
| 6    | 3      | 2 3 1                | ‚ùå Fallo (reemplaza 0) |
| 7    | 0      | 0 3 1                | ‚ùå Fallo (reemplaza 2) |
| 8    | 4      | 0 4 1                | ‚ùå Fallo (reemplaza 3) |
| 9    | 2      | 2 4 1                | ‚ùå Fallo (reemplaza 0) |
| 10   | 3      | 2 3 1                | ‚ùå Fallo (reemplaza 4) |
| 11   | 0      | 0 3 1                | ‚ùå Fallo (reemplaza 2) |
| 12   | 3      | 0 3 1                | ‚úÖ Hit                 |
| 13   | 2      | 2 3 1                | ‚ùå Fallo (reemplaza 0) |
| 14   | 1      | 2 3 1                | ‚úÖ Hit                 |
| 15   | 2      | 2 3 1                | ‚úÖ Hit                 |
| 16   | 0      | 0 3 1                | ‚ùå Fallo (reemplaza 2) |
| 17   | 1      | 0 3 1                | ‚úÖ Hit                 |
| 18   | 7      | 7 3 1                | ‚ùå Fallo (reemplaza 0) |
| 19   | 0      | 7 0 1                | ‚ùå Fallo (reemplaza 3) |
| 20   | 1      | 7 0 1                | ‚úÖ Hit                 |

Resultado final:
- Faltas de p√°gina: 15
- Hits: 5

#### Reemplazo de P√°ginas √≥ptimo - OPT

Cuando hay un fallo de p√°gina (la p√°gina no est√° en memoria), y no hay marcos libres, el algoritmo reemplaza la p√°gina que ser√° utilizada m√°s adelante en el futuro m√°s lejano o que no ser√° usada nunca m√°s. Se reemplaza la p√°gina cuya pr√≥xima aparici√≥n est√© m√°s lejos en el futuro.

Al ser un algoritmo futurista, es imposible implementarlo. Por lo que no se utiliza en la practica.

#### Menos recientemente utilizado - LRU

Selecciona como v√≠ctima la p√°gina que no ha sido utilizada hace m√°s tiempo. Busca aproximarse al comportamiento √≥ptimo (OPT), pero utilizando el historial de uso reciente en lugar de predecir el futuro. Requiere soporte de hardware. Sigue la siguiente secuencia:
1. Se lleva un registro del √∫ltimo uso de cada p√°gina.
2. Cuando ocurre un fallo de p√°gina, se elige la p√°gina que m√°s tiempo lleva sin ser referenciada.
3. Esa p√°gina se reemplaza y se actualiza el estado de acceso.

|‚úÖ **Ventajas**|‚ùå **Desventajas**|
|---------------|-------------------|
|Libre de anomalia de Belady|Requiere m√°s hardware|
|Se aproxima a OPT(mas rapido que FIFO)|Dificil implementaci√≥n|

Ejemplo:

- Cantidad de frames disponibles: 3
- Cadena de referencia: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1

![](/imgs/clase-6/Memoria%20Virtual/Algoritmo%20LRU.png)

| Paso | P√°gina | Estado de los marcos | Acci√≥n                |
| ---- | ------ | -------------------- | --------------------- |
| 1    | 7      | 7 \_ \_              | ‚ùå Fallo (inserta 7)   |
| 2    | 0      | 7 0 \_               | ‚ùå Fallo (inserta 0)   |
| 3    | 1      | 7 0 1                | ‚ùå Fallo (inserta 1)   |
| 4    | 2      | 2 0 1                | ‚ùå Fallo (reemplaza 7) |
| 5    | 0      | 2 0 1                | ‚úÖ Hit                 |
| 6    | 3      | 3 0 1                | ‚ùå Fallo (reemplaza 2) |
| 7    | 0      | 3 0 1                | ‚úÖ Hit                 |
| 8    | 4      | 4 0 1                | ‚ùå Fallo (reemplaza 3) |
| 9    | 2      | 2 0 1                | ‚ùå Fallo (reemplaza 4) |
| 10   | 3      | 3 0 1                | ‚ùå Fallo (reemplaza 2) |
| 11   | 0      | 3 0 1                | ‚úÖ Hit                 |
| 12   | 3      | 3 0 1                | ‚úÖ Hit                 |
| 13   | 2      | 2 0 1                | ‚ùå Fallo (reemplaza 3) |
| 14   | 1      | 2 0 1                | ‚úÖ Hit                 |
| 15   | 2      | 2 0 1                | ‚úÖ Hit                 |
| 16   | 0      | 2 0 1                | ‚úÖ Hit                 |
| 17   | 1      | 2 0 1                | ‚úÖ Hit                 |
| 18   | 7      | 7 0 1                | ‚ùå Fallo (reemplaza 2) |
| 19   | 0      | 7 0 1                | ‚úÖ Hit                 |
| 20   | 1      | 7 0 1                | ‚úÖ Hit                 |

Resultado final:
- Faltas de p√°gina: 12
- Hits: 8

#### M√°s frecuentemente utilizada (MFU) / Menos frecuentemente utilizada (LFU)

Se utiliza como LRU. Pero, en lugar de registrar el tiempo, se registra la cantidad de invocaciones al frame.

|‚úÖ **Ventajas**|‚ùå **Desventajas**|
|---------------|-------------------|
|Libre de anomalia de Belady|Requiere m√°s hardware|
||Dificil implementaci√≥n|
||Bajo rendimiento|

#### Bit de Referencia

Es un bit asociado a cada p√°gina en memoria que indica si la p√°gina fue accedida recientemente. Sigue la siguiente secuencia:
1. Cuando inicia la ejecuci√≥n, el bit esta apagado
2. Cada vez que se referencia el frame, el bit se enciende
3. Periodicamente el SO resetea el bit
4. Ante un fallo, se aplica FIFO ente los que tengan el bit apagado

#### Columna de Referencia

Similar a bit, Es un registro de varios bits que refleja el historial reciente de accesos a la p√°gina en in intervalo de reseteo. Sigue la siguiente secuencia:
1. Cuando ejecuta el SO el reset, hace un right shift del valor a la siguiente posici√≥n y se decsarta el bit menos significativo.
2. Ante un fallo, se aplcia el FIFO entre los que tengan el valor de la columna mas bajo

#### Segunda Oportunidad

Similar a bit de referencia. Mantiene un apagador del bit. Ante un fallo:
- bit = 0 => Se reemplaza
- bit = 1 => Se le da una segunda oporttunidad y no se remplaza. Se pone el bit en 0, se mueve la pagina al final de la cola y se continua con la siguiente pagina

#### Segunda Oportunidad Mejorada

Cada p√°gina ahora tiene 2 bits:
- Bit de referencia (R): indica si fue usada recientemente.
- Bit de modificaci√≥n (M): indica si fue modificada.

Se eval√∫a en este orden de prioridad al buscar qu√© p√°gina reemplazar:

- R = 0, M = 0 ‚Üí P√°gina no usada ni modificada ‚Üí ideal para reemplazo.
- R = 0, M = 1 ‚Üí No usada pero modificada ‚Üí reemplazable, pero requiere escritura a disco.
- R = 1, M = 0 ‚Üí Usada pero no modificada ‚Üí se deja.
- R = 1, M = 1 ‚Üí Usada y modificada ‚Üí tambi√©n se deja.

Si no se encuentra una p√°gina en los primeros grupos, se puede reiniciar los bits de referencia y repetir la b√∫squeda.

### Como Asignar Frames a los Procesos

Este tema responde a la pregunta:

> ¬øC√≥mo se asignan los marcos (frames) de memoria f√≠sica a los procesos del sistema?

El n√∫mero m√≠nimo de marcos que puede necesitar un proceso depende de la arquitectura del sistema y del tipo de instrucciones que ejecuta. Ejemplo:

> Si una instrucci√≥n de CPU permite realizar una suma entre dos operandos directos en memoria y almacenar el resultado en otra direcci√≥n:
> - 1 marco para el c√≥digo
> - 2 marcos para los operandos
> - 1 marco para el resultado
> 
> Total minimo: 4 frames

<!-- 
Se trata del proceso mediante el cual se decide cu√°ntos marcos de memoria (de la RAM) se asignan a cada proceso. Esto puede hacerse:
- Inicialmente (cuando el proceso comienza).
- Durante la ejecuci√≥n, si se permite modificar esa asignaci√≥n.

> Ejemplo: Supongamos que
> 
> - Memoria f√≠sica total: 1024 KB.
> - Tama√±o de p√°gina y marco: 4096 bytes (4 KB) ‚Üí  256 marcos.
> - Tama√±o del SO: 248 KB ‚Üí 62 p√°ginas.
> - Tama√±o Restante: 776 KB ‚Üí 194 p√°ginas.
> 
> Cuando los procesos comienzan a ejecutarse, se les van asignando marcos conforme vayan produciendo fallos de p√°gina (page faults). Cuando ya no queden marcos libres, el sistema debe utilizar un algoritmo de reemplazo de p√°gina.
-->

#### Algoritmos de reemplazo de P√°ginas

Cuando ocurre un fallo de p√°gina, el sistema debe decidir qu√© p√°gina reemplazar. Esta decisi√≥n puede tomarse considerando diferentes √°mbitos:

- **Reemplazo Local**
  -  Objetivo: Mantener estable la asignaci√≥n calculada inicialmente.
  -  Funcionalidad: Las √∫nicas p√°ginas que se considerar√°n para su intercambio ser√°n aquellas pertenecientes al mismo proceso que el que caus√≥ el fallo.
- **Reemplazo Global**
  - Los algoritmos de asignaci√≥n determinan el espacio asignado a los procesos al ser inicializados. 

- **Reemplazo Global con Prioridad** ->

### Hiperpaginaci√≥n

La hiperpaginaci√≥n sucede cuando la frecuencia de reemplazo de p√°ginas es tan alto que el sistema no puede avanzar, y casi todo el trabajo es realizado con overhead. Se puede dar 2 casos:
- Local -> Algunos de los procesos tiene pocos frames asignados
- Global -> Hay demasiados procesos activos y la memoria f√≠sica es insuficiente para todos.

**‚ö†Ô∏èSintomas:**
- üìà Aumento en la tasa de page faults.
- üêå Accesos a memoria m√°s lentos.
- üîª Disminuci√≥n en la utilizaci√≥n del CPU.
- ‚õî El sistema no realiza trabajo √∫til, solo se dedica a paginar.

**üõ†Ô∏è Soluciones**
- üîΩ Reducir el grado de multiprogramaci√≥n -> Menos procesos ejecut√°ndose = menos presi√≥n sobre la memoria.
- üí§ Suspender o eliminar procesos -> Liberar recursos para los procesos realmente activos.
- üß† Agregar m√°s memoria f√≠sica (RAM)

## Sistemas Mixtos (Segmentaci√≥n con Paginaci√≥n)

### Definici√≥n

Esta t√©cnica combina lo mejor de dos mundos `Segmentaci√≥n l√≥gica + Paginaci√≥n f√≠sica`. La direcci√≥n virtual se divide en tres partes:
1. `s` -> Segmento
2. `p` -> P√°gina
3. `o` -> Desplazamiento

No es posible el intercambio de pagina y segmento en el direccionamiento. Porque los segmentos pueden tener paginas y que las paginas tengan distintos segmentos, no tiene sentido.

### Funcionamiento

![](/imgs/clase-6/Segmentaci√≥n%20y%20Paginaci√≥n.png)

1. El espacio l√≥gico del programa se divide en segmentos (porciones funcionales como c√≥digo, datos, stack, etc.).
2. Cada segmento se divide en p√°ginas del mismo tama√±o que los marcos de la memoria f√≠sica.
3. Cada proceso tiene una Tabla de Segmentos, y cada segmento apunta a su propia Tabla de P√°ginas.
4. Solo se cargan en memoria las p√°ginas necesarias de los segmentos que est√©n en uso (paginaci√≥n por demanda).

### Ventajas y Desventajas

‚úÖ **Ventajas**
- Permite compartir segmentos entre procesos (como bibliotecas compartidas).
- No es necesario cargar todo un segmento en memoria; solo las p√°ginas requeridas.
- Elimina la necesidad de compactaci√≥n, porque los segmentos se dividen en p√°ginas que se ubican en cualquier parte de la RAM.

‚ùå **Desventajas**
- Requiere m√°s hardware para direccionamiento (TLB, tablas jer√°rquicas, etc).
- El proceso de traducci√≥n de direcciones es m√°s lento (m√°s niveles de acceso).
- El sistema operativo ocupa m√°s espacio por las m√∫ltiples estructuras de control (segmentos + p√°ginas).
- Aumenta la fragmentaci√≥n interna, ya que puede sobrar espacio dentro de cada p√°gina si el contenido del segmento no la completa.